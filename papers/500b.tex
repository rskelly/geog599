%%  Doesn't work... \usepackage{apacite}	% for APA format; requires sudo apt-get install texlive-bibtex-extra

\documentclass[10pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{siunitx}
\usepackage{setspace}	% for line spacing
\usepackage{calc}		% for figure scaling
\usepackage{svg}		% for graphics
\usepackage{graphicx}	% for graphics
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}

\fontfamily{ptm}

% Images are build by calling images/generate.sh <images> <output> where
% output is the "build" directory used by Texmaker.
\graphicspath{{./build/images/}}

\author{Rob Skelly}
\title{Real-Time Terrain Following and Trajectory Adjustment for Remote-Sensing Unmanned Aerial Vehicles}


\begin{document}

\maketitle

\doublespace

\section{Introduction}

Remote sensing is the art and science of sensing, or measuring, objects without the necessity of direct physical contact between the subject and the observer. Three of the human sense organs --- the eyes, ears and nose --- are remote sensing instruments, though remote sensing more commonly refers to the quantitative observation of objects on the Earth, in a geospatial context, using technology designed for this purpose. Remote sensing instruments are typically mounted on air- or spacecraft, though they can just as easily be handheld or tripod-mounted. Such instruments might include a spectrometer for measuring the electromagnetic reflectance of an object or a laser rangefinder scanner (LiDAR) for describing its structure in three dimensions. Satellite and airborne remote sensing have many use-cases, from tracking sea ice extent \cite{Dierking2006,Shuchman2004}, to estimating standing timber volumes \cite{Allouis2011,Tonolli2011}, to investigating plant health at the scale of a single leaf \cite{Palou2013}.

The scale of the phenomenon under investigation, in part, determines the distance from the instrument to the subject. Sea ice, for example, must be observed at a hemispheric scale from a high-orbit satellite, while a study of the fine structure of individual plants must be performed at a much smaller remove. A large resolution of 25m-1000m \cite{Shuchman2004} might be suitable for the study of Arctic ice extent while 5cm or less \cite{Palou2013} would be appropriate for the study of plant health at the leaf level. 

The subject distance has a deterministic relationship with the resolution of a given instrument, where resoluton is defined as the minimum size of object that can be discriminated. If an object is larger than the resolution of an individual element in a spectrometer, that element's specta will be pure --- they will not be contaminated by those of surrounding objects. If, on the other hand, the object is smaller than the instrument's resolution, the spectra will be mixed. This hampers the researcher's ability to accurately identify objects in the image \cite{Lillesand1999}. In the case of point data, such as that produced by LiDAR, increasing the subject distance reduces the point density which, in turn, reduces the number of points associated with an object of interest. In this case, the power of any statistical analysis of points related to that object is reduced. 

The resolution of an instrument is determined by its instantaneous field of view (IFOV), that is the solid angle around the instrument's measurement axis, within which it is sensitive to incoming information \cite{Lillesand1999}. Resolution, subject distance and IFOV are related by the identity, 

\begin{equation}
r = d \theta
\label{eq:ifov}
\end{equation} 
where $r$ and $d$ are the resolution and distance linear units and $\theta$ is the IFOV in radians \cite{Lillesand1999}. A similar relation exists between platform elevation and the point density of a LiDAR instrument, where the scan angle is analogous to the IFOV. 

A side effect of the relation in eq. \ref{eq:ifov} is that changes in the subject distance induce along track (for a moving instrument) scale distortion in the image. As an example, figure \ref{fig:scale_cam} shows a nadir-aligned camera with the black object twice as far from the instrument as the white object. In the image view (figure \ref{fig:scale_img}), the nearer object appears twice as large --- and therefore twice as detailed --- as the far one. 

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/scale_topography_cam.pdf_tex}
\caption{Side view of nadir-aligned camera with subjects.}
\label{fig:scale_cam}
\end{figure}

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/scale_topography_img.pdf_tex}
\caption{Resulting image with scale distortion.}
\label{fig:scale_img}
\end{figure}

It is clear that subject distance and, therefore, platform elevation, in the case of airborne instruments, have important effects on the quality of remotely-sensed data. It follows that, in the interest in maintaining the resolution and point density of remotely-sensed data, it is necessary to control the elevation of an airborne platform to account for variation in the terrain elevation, particularly at lower elevations and smaller scales, where such variations have a relatively larger effect. In the case of unmanned aerial vehicles (UAVs), where the pilot is not with the vehicle and cannot monitor and control its elevation with sufficient accuracy, this must be automated. This ability is called terrain-following (figure \ref{fig:uav_terrain}).

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/uav_terrain.pdf_tex}
\caption{Terrain-following UAV.}
\label{fig:uav_terrain}
\end{figure}

The current explosion in interest in UAVs for everything from home delivery to remote sensing to toys to military applications, has made compact UAVs more accessible to researchers than previously. Commercial-grade UAVs with payload capacities of over 6kg are now common, and at reasonable prices. However the use of UAVs for scienctific purposes, though growing, is still fairly new and use-appropriate control systems are a field of rapid development. For remote sensing applications, the need for accurate terrain following systems is being felt. Terrain following contributes not only to the safety of the vehicle and people, animals and property within the study area, but has a profound influence on the quality of data as explained previously. 

Coincidentally, there is a simultaneous explosion of interest robotics, and especially autonomous automobiles, which has encouraged numerous companies to rush to market with compact LiDAR devices of various types \cite{Quanergy2017,Dormehl2017,Morin2017}. These devices are designed to be light, durable and affordable and are meant to give robots and cars the ability to sense their surroundings in three dimensions, in order to navigate safely through their environment. They happen to be ideal (at least in form and cost) for use on UAVs, both for remote sensing applications, and for autonomous vehicle control.

Unfortunately, the state of the art in battery technology is not adequate to the power requirements of heavily-laden remote-sensing UAVs. The overuse of battery resources entails significant costs in terms of mission turn-around time and expense, in terms of the number of flights required to cover a study area and the number of sets of batteries required to complete a mission. The extra mass and power draw of extra rangefinders for terrain following exacerbates this problem.

These issues motivate the present research and the questions:

\textbf{For a remote sensing unmanned aerial vehicle,
\begin{enumerate}
\item what type and arrangement of laser rangefinder instrument(s) is best suited to the task of real-time terrain following, and;
\item what is the optimal vertical trajectory function, in terms of the stability of resolution and point density, the safety of the platform, and the conservation of on-board power?
\end{enumerate}}

Obtaining and testing all of the available --- and not-yet available --- laser rangefinders would be costly and time-consuming. This project will attempt to design computerized simulations of a variety of instruments and configurations by sampling from a variety of modelled terrains. Such terrains can be represented by mathematical models, such as planes and unions of geometric shapes, or collected from the real world by LiDAR devices and resampled. The sampling pattern and density will be modified to resemble the output of various laser rangefinders, and noise will be added to simulate the instruments' error charactristics. An important benefit of simlation is the ability to eliminate environmental factors and isolate the true benefits of one system over the other.

This research will be concerned with optimizing data quality for two types of instruments, a hyperspectral push-broom scanner, and a rotating multi-beam LiDAR scanner, and will attempt to quantify the distortions induced in each by the chosen terrain-following strategy. Ultimately, a multi-rotor UAV will be outfitted according to the results of the simulation for testing.

\section{Background}

\subsection{LiDAR}

Light detection and ranging (LiDAR) is a relatively new technology which uses laser pulses to measure the distance from the instrument to a surface. The typical LiDAR-equipped vehicle will use the global positioning system (GPS) for geodetic positioning, an inertial navigation system (INS) for measuring the inertial moments (attitude, angular velocity), a highly accurate clock, a computer and the laser instrument itself \cite{May2007,Lillesand1999}. LiDAR is considered an "active" sensor, as it provides its own source of energy.

LiDAR works by sending out a pulse of laser light towards an object and recording the reflection of the pulse. The clock determines the time-of-return of the pulse, which is used to calculate the distance that the pulse has travelled. The INS and GPS are then used to convert the polar coordinate of the pulse to a the three-dimensional position of the reflector in Cartesian space, given the known orientation of the vehicle and the fixed position of the laser. 

The laser itself may take many forms. Some LiDAR devices consist of a single, fixed laser while most consist of a single laser with a spinning mirror that creates a linear scan pattern of repeated pusles. In the latter case, the computer has knowledge of the orientation of the mirror and can accurately compute the position of the subject. Recently, LiDAR devices have appeared for the autonomous vehicle market, which feature multiple beams fixed to a spinning rotor. These differ from the spinning mirror type in that, with every revolution, they create multiple scan lines. Used in airborne applications, this causes re-sampling of the subject as the vehicle moves, and may result in a very high-density point cloud. With the advent of autonomous vehicles and the demand for highly reliable, affordable LiDAR devices, solid-state LiDAR is becoming prevalent. Unlike devices with rotating components, solid-state LiDARs have no moving parts and are much less likely to suffer a mechanical failure. These have the side-benefit that they are cheaper to manufacture and potentially much smaller than mechanical LiDARs. Solid state LiDARs are available in single- and multi-beam configurations using multiple emitters, or a single emitter with a splitter.

The pulses sent by the laser are not instantaneous, but consist of waves of light of stable intensity. The LiDAR's receiver reads the returning pulse as a waveform of time versus intensity. It discretizes this waveform and extracts the peaks as individual returns. This enables the device to extract more than one return from a single pulse. The "footprint" of a laser is not infinitely small, but tends to spread with distance. In complex environments, with multiple reflectors along the path of the laser, such as the leaves of a tree, the LiDAR might register returns from the top of the canopy, the ground and from intermediate obstructions. Some LiDAR devices record as many as five returns per pulse \cite{Lillesand1999}.

There are several measures of data quality for LiDAR data, including relative and abolute vertical and horizontal accuracy and point density. Positional accuracy may be degraded by numerous factors including platform position and attitude errors, boresight misalignment, range measurement error, scan angle error and beam divergence error \cite{May2007}, however this is somewhat beyond the scope of this document. Point density represents the number of points that can be found within a unit of continuous space, commonly described by a two-dimensional grid. Because a LiDAR instrument emits a fixed number of pulses per unit time, and because the instrument-to-target distance is proportional to the coverage area, it is clear that point density declines with elevation. 

As a LiDAR-equipped aircraft follows a flight line, a scanning LiDAR scans across the track. The pulses emitted by the instrument strike the ground at $90\degree$ at nadir, but at a highly oblique angle at the ends of the scan line. The obliqueness of this angle has several consequences. First, a pulse striking a target at such an angle is likely to reflect away from the instrument, rather than back towards it; second, the increased distance that the pulse must travel increases the magnitude of the error inherent in the measurement (which is then inconsistent with the error at nadir); third, the pulse is striking the subject from the side, rather than the top, as intended. These issues are exacerbated when the platform's roll angle is non-zero. It is therefore common to filter out points within a certain distance of the flight line edge. The removal of edge points is compensated for, to some degree, by flying parallel lines with substantial overlap, up to 50\%. With this amount of overlap, every subject is effectively scanned twice.

A further density-related issue, and one directly impacted by the subject of this research, is the role that platform pitch plays in the variability of point density. If the platform accelerates in the fore or aft direction, it will pitch forward slightly, angling the scanner towards the aft, creating a region of increased point density. However, if the vehicle slows, it will pitch rearward, creating a region of reduced density. Clearly it is desireable to minimize variations in platform pitch.

Point density has scale-determined implications for research. If a researcher is attempting to describe the canopy structure of 90m-tall old-growth forests, a high platform elevation is required to both to cover a large enough area to acquire a significant number of crowns, but minimize the variance in point density between the ground and the tree top. Fortunately, the point density required for the study of such enormous plants is much lower than that required for, say, a single grape vine, where a researcher may be interested in the orientation of individual leaves. To characterize the structure of a grape vine, point density must be suitably high, which, using the same instrument as above, requires a lower flight elevation. If a vinyard is situated in a valley with considerable relief, the variance in point cloud density at a constant elevation may reduce the data quality in lower-elevation  parts of the study area.

These two issues, point density and flight-line overlap, are manageable so long as the variation in platform elevation relative to the subject is minimized. There are two ways to accomplish this: first, by rasing the platform to a sufficient elevation to minimize the variation in point density; second, by following the terrain at a constant relative elevation.

\subsection{Hyperspectral Imaging}

A hyperspectral sensor, or imaging spectrometer is a passive sensor that measures reflected light in very narrow spectral bands. Some such scanners can record over 400 such distinct spectra. There are two primary types of hyperspectral sensor, the push-broom scanner, which is an array of sensor elements oriented across the scanning direction, and the whisk-broom scanner, in which an array of elements aligned with the scanning direction sweeps side-to-side across it \cite{Lillesand1999}. 

The advantage of a hyperspectral scanner over a multi-spectral scanner, such as the Landsat Thematic Mapper, is the narrow width of its spectral bands. For example, band 7 of the Landsat TM instrument is $0.27\si{\um}$, while a typical hyperspectral scanner will record bands of $0.01\si{\um}$ in width \cite{Lillesand1999}. Just as a high spatial resolution reduces the mixing of spectra in a pixel, a high spectral resolution reduces mixing within spectra. If, for example, there is an absorbtion feature somewhere within Landsat's band 7, it will be impossible to discern. A collection of narrower  bands across the same span of wavelengths will be able to resolve the feature. 

A major issue with all spectrometers is the interaction between light and the atmosphere. The ultimate goal of spectometry is to determine the reflectance of a surface, which is presumed to correlate with some characteristic of or process within the underlying object. In a vacuum, reflectance is simply the ratio between irradiance (energy from the source) and radiance (energy reflected from the subject). However, under natural conditions, the spectrometer measures radiance plus enery reflected from the atmosphere between the sensor and the surface (path radiance). Irradiance is then the sum of attenuated light sources, generally the sun and incident radiation from the atmosphere \cite{Lillesand1999}. Unfortunately, these atmospheric effects cannot be ignored, even at the low elevations flown by UAVs. However, the variations can be minimized by maintaining a constant elevation.

Platform elevation has several effects on hyperspectral data quality, aside from atmospheric effects. The first of these is the effect on resolution, as discussed above: as the platform rises, the sensor's spatial resolution declines. Another effect is on the ratio of signal to noise. Each element of a hyperspectral scanner captures a discrete value by recording incoming radiation for a specified interval, called the intergration time. For a given platform velocity and integration time (which are set during the planning phase of the mission), the amount of energy received by an element is proportional to the area of visible reflective surface, which is in turn proportional to the platform's elevation. Since the instrument noise is constant, the reduced proportion of incoming energy reduces the signal-to-noise ratio. In order to maintain this ratio despite variations in elevation, the platform must either adjust its speed or the sensor's integration time, which is not currently possible in real time.

These issues, resolution, signal-to-noise and atmospheric interference, can be minimized by following the terrain at a constant relative elevation.

\subsection{Terrain Following}

Research into terrain following has been continuing since the 1960s for the control of ballistic missiles and jet aircraft \cite{KRACHMALNICK1968,Starling1971,Cunningham1980}. Such systems use a forward- and downward-facing RADAR rangefinder to detect the terrain elevation some distance ahead of the vehicle, some means of terrain classification \cite{Cunningham1980}, and a method of altering the vehicle's trajectory to follow the terrain surface as closely as possible. Research on terrain following for military aircraft and missiles has been focused on high-speed, low elevation flight with a premium placed on stealth, speed, efficiency and safety \cite{KRACHMALNICK1968}. It is important to note the distinction between terrain following and terrain avoidance, here: missiles and military aircraft must fly low to avoid detection by radar and interception by surface-to-air or airborne weapons. Neither high speed nor stealth are desireable for a remote sensing mission but many of the insights from this research are nevertheless applicable to remote-sensing UAVs.

The key feature of these terrain following systems is their predictive, rather than reactive, nature. Most existing UAV terrain following systems use either a nadir-aligned rangefinder and a feedback loop for adjusting the vehicle's elevation to a predetermined value in real time \cite{ArduPilot2017}, or a pre-exiting elevation model which is interpolated to generate a three dimensional flight path \cite{ArduPilot2017,Samar2011}. Military terrain following systems provide both the ability to adaptively respond to terrain without pre-planning, and the ability to optimize their flight plans in flight with some degree of foresight.

Starling \cite{Starling1971} envisioned a RADAR-based system featuring a virtual "ski" sliding on the terrain ahead of, and in alignment with, the aircraft. As the ski encountered a rise, its axis would intersect that of the aircraft, generating a climb-command, causing the aircraft to climb. As the ski rode the terrain down again, the axes of the aircraft and the ski would diverge, generating a descend-command. This feature had the valueable quality that on low-frequency terrain, the aircraft would follow it closely. On high-frequency terrain, the aircraft woud tend to smooth the terrain, following a trajectory that would not exceed the gravitational tolerances of the pilot (about 1g).

Lu and Pierson's \cite{Lu1995} documented a method for terrain-following in a fixed-wing aircraft by exploiting the lift and drag properties of the vehicle and "bang-bang" (on/off) throttle control. This isn't necessarily useful for the design of flight controls for multi-copters (which have essentially zero lift) but the authors' insights into the meaurement of power use are helpful. 

Alqahtani and Emron \cite{Alqahtani2018} devised a system using using downward- and forward-facing single-beam rangefinders to anticipate terrain undulations, and developed 

\cite{Alqahtani2018,Bolandi2013} -- Kinematics

The use of a full, 3-dimensional point cloud and ground classification algorithms have not been studied for the purpose of terrain following, perhaps because the LiDAR devices small enough for use on such vehicles are a recent innovation. The optimisation of trajectory functions for data quality maintenance and power conservation have also not appeared in the literature. 

\subsection{Implications for Remote Sensing UAVs}

A standard multi-rotor UAV moves by coordinating its thrust and attitude. Unlike a fixed-wing aircaft, which uses control surfaces on its wings, or a helicopter, which tilts its main rotor(s), a mutli-rotor UAV must rotate its chassis to direct the downwash of its fixed rotors and thus its fore, aft and lateral movements. This, too, has an impact on data quality. As the vehicle rotates, its instruments move away from their nadir orientation. 

A hovering UAV requires an amount of thrust (measured in Newtons, $N$) equal to the downward force on the vehicle, given by, 

\begin{equation}
f = ma,
\label{eq:hover_force}
\end{equation} where $f$ is the downwad force, also in Newtons, $m$ is the mass of the vehicle in kg, and $a$ is the acceleration of gravity on Earth, approximately $9.8m/s^2$. A UAV moving forward at a steady state requires an amount of thrust equal to the hovering thrust plus an additional force to maintain altitude while it moves horizontally. This is given by,

\begin{equation}
v_i = \dfrac{ v_h^2 } { \sqrt{ (v_\infty \cos \alpha)^2 + (v_\infty \sin \alpha + v_i)^2 } } 
\label{eq:move_force}
\end{equation}, where $\alpha$ is the angle of attack, $v_\infty$ is the free stream speed (platform velocity plus wind) and $v_h$ is the hover velocity \cite{Hoffmann2007}.

When a UAV encounters a change in terrain elevation it must adjust its trajectory. Due to the inertia of the platform, the change in velocity is  necessarily delayed until some time after the vehicle's thrust and attitude have been adjusted. It is thus impossible for a vehicle to follow a terrain exactly using a purely reactive system without backtracking. As an extreme example, if the vehicle approaches a vertical cliff, its horizontal velocity must drop from the nominal flight velocity to zero and its vertical velocity must change from zero. During the deceleration, the sampling density will increase until, during the ascent, the instruments will continue to sample the same ground repeatedly. After the ascent, there will be a brief flight over terrain that is at the original elevation while the vehicle is at the new elevation. Scale distortion in this region will be maximized. Also at this time, the vehicle will be accellerating in the horizontal direction, causing over-sampling. These anomalies will have to be rectified in post-processing. Alternatively, the vehicle can follow a smoothed trajectory which departs from the nominal flight elevation but preserves the vehicle's horizontal velocity (figure \ref{fig:uav_smooth_traj}). In this case, scale distortion is induced in the data, but the sampling density remains constant. In either case, the vehicle must anticipate the change in trajectory in order to successfully follow the terrain without contacting the cliff face or reversing over ground that has already been covered.

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/uav_smooth_trajectory.pdf_tex}
\caption{Zero-velocity and smoothed trajectory adjustments. Black arrows indicate regions of scale distortion. Dashed arrows indicate regions of over-sampling due to changes in horizontal velocity.}
\label{fig:uav_smooth_traj}
\end{figure}


With a forward-facing sensor, the problem of an approaching obstacle is easily resolved, but descending presents another problem. As the vehicle approaches the lip of the cliff, the terrain below the face is occluded by its edge (figure \ref{fig:uav_edge_occlude}), depriving the vehicle of elevation information that it needs to optimize its trajectory. With a single-beam rangefinder, at one timestep, the lip will be sampled, and at the next, the ground will be sampled. The vehicle can estimate the terrain as the convex hull of these elevations, and derive a trajectory based on this modelled terrain, but it cannot revise this estimate or its trajectory without a rangefinder with a broader vertical field of view. A similar phenomenon occurs when the vehicle is traversing down a slope that does not intersect with the rangefinder's beam. If the end of the slope is beyond the instrument's range, the vehicle loses contact with the ground and has no information from which to compute a trajectory.  Ideally, the vehicle could have a sensor that is sensitive from nadir to the horizon, and adjust its trajectory iteratively as it approaches the edge. 

*** The power required by the vehicle following any trajectory can be calculated by taking the integral of the function decribing the thrust or power curve. This curve will be something like figure \ref{fig:uav_power_curve}.

To identify a sufficient advance angle for a forward-facing sensor, it is necessary to first calculate the time reqired for a UAV to change its velocity. At the extreme, in the case of the vertical cliff, this is the time required to reduce the vehicle's horizontal velocity to zero. It would be a simple matter to calculate the time required for the vehicle to decelerate given its mass, available thrust, velocity and environmental conditions. However, owing to the fact that a multi-copter must control its speed by pitching, which should be minimized to protect image quality, the rate of deceleration should be carefully considered. The advance warning

\begin{equation}
T_d = \dfrac{v}{\sin(\theta) * E}
\label{eq:decel}
\end{equation} 

\begin{figure}
\centering
\def\svgscale{0.8}
\input{build/images/uav_power_curve.pdf_tex}
\caption{The power curve of a terrain-following event.}
\label{fig:uav_power_curve}
\end{figure}


\begin{figure}
\centering
\def\svgscale{0.8}
\input{build/images/uav_edge_occlude.pdf_tex}
\caption{Rangefinder occlusion on obstacle edge.}
\label{fig:uav_edge_occlude}
\end{figure}

\subsection{Rangefinder and Algorithm Selection}


.  at a given velocity and direction. This is dependent on the mass of the vehicle, its available thrust, the acceleration of gravity and the direction of travel. Temperature, wind and other conditions also play a role. 

TODO: Problems with crabbing.

A spectrometer (i.e., an RGB camera) with a wide-angle lens will cover the desired field of view at high resolution and low cost, but will require computationally-intensive photogrammetric or optical-flow processing to extract range measurements. These methods work only when the platform velocity is sufficient to induce detectable changes in the pixel array. Also, spectrometers are passive sensors, meaning they record reflected light from variable environmental sources, specifically the sun. Tracking changes in intensity or colour across the pixel array becomes difficult without the consistency of a controlled energy source, or on low-contrast surfaces, hampering the detection of objects which would be used to compute ranges.

One or more single-beam laser range finders can be mounted statically, on a scanning gimbal or in a mixture of configurations. Laser rangefinders are active scanners that emit laser pulses and measure the time of return from a subject to compute the subject distance. Environmental conditions and scene contrast are not likely to affect measurement accuracy, however point density reduced by scattering, absorbtion or reflection on some surfaces. 

Finally, if the main sensing LiDAR is a rotating multi-beam type, it can be rotated slightly forward so that the rear laser points to nadir, and the front laser points forward. Rotating multi-beam scanners such as the Velodyne VLP-C32 differ from standard aerial LiDARs in that, whereas the latter uses a single laser and a rotating mirror to scan the ground, the former uses multiple lasers mounted on a rotating head; insead of a single scan line, the Velodyne creates 32 scan lines on every rotation. The difference is due to the intended application of the scanner, the aerial instrument need only produce a 2-dimensional scan on each rotation, which will be assembled into a 3-dimensional point cloud in post-processing; a car-mounted instrument must produce a 3-dimensional model of the environment on every rotation.

Because the lasers in a rotating multi-beam scanner revolve around the same axis, each beam forms a cone of light as it does so. When these cones of light intersect a planar surface, they project a parabolic scan line.

, which provides a $40\degree$ vertical and $360\degree$ horizontal field of view, can be mounted vertically to give wide swath that extends from nadir to the horizon. The point density of such instruments can provide a highly accurate and detailed model of the terrain, but they are currently heavy and expensive. 


The analysis should consider a parameter that adjusts the transition distance (i.e., smoothing) between zero and some limit, in consideration of the impact on data quality.

Unlike missiles and jet aircraft, the attitude of an aerial remote-sensing vehicle is of utmost importance. Nadir-aligned sensors should remain as close to nadir as possible. While it is possible to rapidly change a vehicle's velocity, doing so requires radical changes to the thrust and attitude of the vehicle which disrupts the alignment of the instruments and degrades the data quality.



Studies into missiles and high-speed jet aircraft carefully consider the role of inertia, drag, thrust, lift and other dynamic effects on the airframe so that the autopilot system can anticipate changes in terrain. 

** The aircraft attitude is important to data quality. We can't just halt the platform by applying maximum thrust and pitching upward. The aircraft must either coast to a velocity which permits smooth transititions in trajectory without disrupting the attitude, or it must smooth its trajectory: a compromise.



How to follow closely behind hills, etc. 

How to anticipate and adjust for upcoming changes.

Following digital surface or terrain: DIFFFERENT!

no need for attitude adjustment -- want to avoid it




\subsection{Remote-Sensing UAVs}

This research will concentrate on the control of multi-rotor UAVs carrying hyperspectral and LiDAR instruments.

UAVs offer many advantages over traditional, manned aerial platforms. First among these is cost. Fixed-wing and rotary surveys may cost thousands of dollars per flight-hour. The instrumentation required for such surveys may cost hundreds of thousands or millions  of dollars. Flight planning and execution of a UAV survey can be accomplished rapidly, and changes to a flight plan do not represent a significant delay or expense. A UAV survey need not originate at an airport. The training required to operate a UAV in accordance with federal regulations, while substantial, is trivial in comparison to pilot training and certification, and a UAV pilot need not be dedicated to the profession. Most importantly, the low platform elevation of a UAV survey radically increases the attainable resolution for raster products and point density for LiDAR products.

There are mechanisms for enabling “terrain following” for UAVs, which depend on the pre-existence of a digital surface model (DSM.) This has two consequences: first, that the survey must have been performed previously and the resulting data processed into a DSM; second, that the DSM must be of sufficient quality, accuracy and detail to control the UAV safely, given the nature of the terrain, ground cover and the flight elevation. Currently-available solutions use the Shuttle Radar Topography Mission (STRM) elevation model, which is one of few freely-accessible global DEMs, but is not a true DSM; C-band RADAR may penetrate up to half way into a forest canopy \cite{Carabajal2005} and will penetrate into snow, depending on its porosity and wetness \cite{Tighe2009}. The maximum resolution of the SRTM DEM is30' (approximately 30m) horizontally and 1m vertically, with stated vertical accuracy of $\leq$16m, much too large for low-elevation remote sensing work, particularly in steep or forested terrain.  

An ideal solution would be for the UAV to compute a terrain model on its own, in real time, and follow the terrain at a fixed elevation while executing its flight plan. The system provides an opportunity to implement obstacle avoidance: objects that are identified as non-ground, yet obstruct UAV’s trajectory may be used to signal a return-to-home response, or a go-around plan and, depending on the uncertainty inherent in the instrument, the point cloud generated by a forward-facing laser may be contributed to that of the downward-facing main LiDAR, both to densify it and to contribute views of the subject from fore and aft, rather than only left and right, as is typical. 



\subsection{SLAM}

Simultaneous localization and mapping.

Traditional terrain-following mechanisms used RADAR for measuring the distance from aircraft to terrain. The advent of cheap, lightweight LiDAR instruments, primarily designed for the autonomous vehicle market, has made available 


The Kalman Filter \cite{Kalman1960} is a recursive least-squares optimizing function that effectively converges on a true value -- in one or more dimensions -- at each time step by assigning a weight to the current state and the inputs depending on the confidence in each, and generating a new state estimate which will be subjected to the same process on the next time step. A primary consideration in the development of state-space smoothing methods such as Kalman's is the impossibility of storing a complete history of the object's state and estimating its immediate future based on its entire past. The latter would entail an ever-increasing processing load, as the object's history grew. Another consideration is the temporal variability in the certainty of new estimates of the object's state (i.e. measurements). As these vary through time, they would also have to be stored and computed to derive an estimate of the object's state. The Kalman filter solves these problems by considering only the object's present state, the inputs, and an error estimate for each \cite{Swerling1959}. 

Kalman filtering was originally used for estimating the trajectories of the Apollo lunar landers and for RADAR tracking of targets \cite{Grewal2010}, but is widely used in climate science, econometrics, engineering, especially in the field of robotics. Autonomous robots, UAVs included, must have reliable information their position, orientation and velocity in order to interac effectively with the environment. Airborne vehicles, in particular, must have accurate information about their position and orientation, but also their trajectory.

A typical UAV uses the Global Positioning System (GPS) for absolute positioning and an inertial navigation system (INS) for measuring acceleration and orientation. These inputs together allow the vehicle to ajust its attitude and velocity to maintain a pre-defined trajectory, and -- arguably, more importantly -- for georeferencing collected data. There are numerous sources of measurement error inherent in GPS and INS measurements which hamper the vehicle's ability to ascertain its instantaneous state; the Kalman filter provides a means of determining its true state with a high degree of confidence.

[Extended Kalman filter -- local linearization?]

\subsection{Trajectory}

...

Discuss current solutions: Maps Made Easy.



\subsection{Ground Classification}

Single-beam vs. multi-beam.

Multi-element vs. planar. \cite{Nobili2015}

The technology for automating ground classification is not mature \cite{Vosselman2001,Vosselman2000} and perfection is, of course, not possible. But what are the implications for UAV control? The point density of the instrument is likely to be limited, as is the capability of processing the full cloud. A higher density is better for classification, but instrument noise and vegetation present serious issues. What if the point cloud cannot penetrate into the canopy? The drone may have some way of reconciling a naive assumption about the nature of the terrain, and the information is receiving from the scanner?


\subsection{Alternatives to LiDAR}

** What if we just use the down-facing lidar and use predictive method to anticipate changes in terrain? Drawback, no obstacle avoidance.

** Photogrammetry -- no penetration.

** Optical flow -- traditional robotics technique, used by insects. Same limitations as photogrammetry.


\section{Development}


\subsection{Simulation}

Given the variety of laser scanner types and configurations, and the variety of terrain and ground-cover types a UAV may encounter, it is prudent to attempt to simulate and assess a variety of virtual instruments and conditions before purchasing hardware. Several rangefinder configurations are listed in figure \ref{list:rangefinder_configs}.

\begin{itemize}
\item Single-beam, single-return.
\item Single-beam, multi-return.
\item Single-beam, single-return with a servo driver for mechanical, side-to-side scanning.
\item Split-beam, multi-return, solid-state.
\item Multi-beam, multi-return, solid-state.
\item single-beam, multi-return, spinning laser.
\item Multi-beam, multi-return, spinning laser.
\item Multi-beam, multi-return, spinning mirror.
%% \caption{Laser rangefinder configurations.}
\label{list:rangefinder_configs}
\end{itemize}

It must also be determined which sampling method is optimal. A static single-beam range finder will produce a series of points in a line along trajectory of the platform. This may be sufficient to detect the surface elevation directly in front of the platform, but may not be robust to noise, may not enable the detection of ground returns, and will not produce a useful side-view when the vehicle is turning. Single-beam lasers are cheap and lightweight, which reduces the load on the platform's power supply. A fan-shaped scanning pattern would produce a 3-dimensional point cloud which would enable ground point filtering, some noise removal and limited side-looking ability in turns. These instruments are more costly and heavier, but may be able to contribute to improved data quality and platform safety. Single-beam rangefinders may be mounted statically or on a servo, which scans back and forth across the terrain in a sinusoidal fasion (figure \ref{fig:sinus_plane}).

The output of any rangefinder can be simulated by defining a terrain-generating function and sampling it at positions that would be read by the instrument. Gaussian noise can be applied to the samples simulate measurement error using the characteristics documented by the manufacturer or testing. In a real-world scenario, it would be neccessary to account for uncertainty about the vehicle's elevation and the actual elevation of the terrain. In a simulated environment these can be controlled, leaving only the optimality of the trajectory to be assessed.

Figure \ref{fig:point_plane} shows an example of the output of a hypothetical regular sampling of a planar surface. The first plot shows the outcome using measurements with zero uncertainty. In the second and third images, the measurements are perturbed by random Gaussian noise with standard deviations of 0.001 and 0.01, respectively, to simulate error.

\begin{figure}
\centering
\def\svgscale{0.25}
\input{build/images/plane_grid_0.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_grid_0001.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_grid_001.pdf_tex}
\caption{Simulated grid sampling of planar surface with Gaussian error; $\sigma 0$, $\sigma 0.01$ and $\sigma 0.001$.}
\label{fig:point_plane}
\end{figure}


Figure \ref{fig:sinus_plane} shows the result when the planar model is scanned in a sinusoidal fasion by a servo-mounted rangefinder.

\begin{figure}
\centering
\def\svgscale{0.25}
\input{build/images/plane_sinus_0.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_sinus_0001.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_sinus_001.pdf_tex}
\caption{Simulated sinusoidal scan of planar surface with Gaussian error; $\sigma 0$, $\sigma 0.01$ and $\sigma 0.001$.}
\label{fig:sinus_plane}
\end{figure}


Figure \ref{fig:linear_plane} shows the result when the planar model is scanned in a linear fasion by a statically-mounted rangefinder.

\begin{figure}
\centering
\def\svgscale{0.25}
\input{build/images/plane_linear_0.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_linear_0001.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_linear_001.pdf_tex}
\caption{Simulated linear scan of planar surface with Gaussian error; $\sigma 0$, $\sigma 0.01$ and $\sigma 0.001$.}
\label{fig:linear_plane}
\end{figure}

Figure \ref{fig:plane_object} shows the result of scanning a plane with a square object using a grid, sinusoidal scan and linear scan.

\begin{figure}
\centering
\def\svgscale{0.25}
\input{build/images/block_grid_0.pdf_tex}
\def\svgscale{0.25}
\input{build/images/block_sinus_0.pdf_tex}
\def\svgscale{0.25}
\input{build/images/block_linear_0.pdf_tex}
\caption{Simulated scans of planar surface with obstacle.}
\label{fig:plane_object}
\end{figure}


Any rangefinder configuration

of these can be simulated by reading an existing real-world or generated point cloud, applying parametric noise and densification, and streaming the points into the navigation system as if they were being produced at flight time by a rangefinder. If a real-world point cloud is used, the measurement error inherent in the original product may be maintained or increased, and it may be densified using the documented nominal uncertainty for the campaign. A modeled terrain, such as a simple plane or three-dimensional polynomial surface, with or without objstructions, can be sampled at an arbitrary density and the samples perturbed using Brownian or Gaussian noise.

Simulate a variety of terrain conditions: Flat, sloped, undulating, etc. with and without obstacles

Generate simulated point clouds as if from a rangefinder or scanner, single or multibeam.

Add parameterized noise to the simulated measurements to simulate real-world noisy measurements.

Generate noisy vehicle position inputs, etc.

LIDAR ACCURACY \cite{May2007}




\subsection{Control}

Control Loops








** Most (all?) current applications use a nadir laser and reactive paradigm. I want to create a smoothed trajectory with configurable limits (for safety) based on a predictive regime. a) from facing forward, and b) from computing trends based on past measurements.

** Kalman filter. Can be used to compute a trajectory from the vehicle’s current state and inputs from instruments, and flight plan. 



Photogrammetry
Still a possibility

Makers:
Velodyne (solid state lidar coming)
Quanergy (S3)
AEye
Leddar (range sucks; 20m @ 18% grey)

Purpose: Build a system that:

\begin{itemize}
\item Ascertains the vehicle's state using GPS and INS inputs and the Kalman filter.
\item Ascertains the elevation some fixed distance in front of the vehicle using a forward-facing rangefinder; multi- or single-beam TBD; ground classification requirements TBD.
\item Adjusts the 2D trajectory using the vehicle's state and future changes in elevation using some smoothing method (possibly Kalman) as well as insight gleaned from other terrain following methods.
\item Controls the vehicle so that it will follow the trajectory.
\end{itemize}


\bibliographystyle{plain}
\bibliography{/home/rob/Documents/bibtex/library.bib}


\end{document}