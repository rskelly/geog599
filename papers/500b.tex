%%  Doesn't work... \usepackage{apacite}	% for APA format; requires sudo apt-get install texlive-bibtex-extra

\documentclass[10pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{siunitx}
\usepackage{setspace}	% for line spacing
\usepackage{calc}		% for figure scaling
\usepackage{svg}		% for graphics
\usepackage{graphicx}	% for graphics
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}

\fontfamily{ptm}

% Images are build by calling images/generate.sh <images> <output> where
% output is the "build" directory used by Texmaker.
\graphicspath{{./build/images/}}

\DeclareUnicodeCharacter{2010}{ }


\author{Rob Skelly}
\title{Real-Time Terrain Following and Trajectory Adjustment for Remote-Sensing Unmanned Aerial Vehicles}


\begin{document}

\maketitle

\doublespace

\section{Introduction}

Remote sensing is the art and science of sensing, or measuring, objects without the necessity of direct physical contact between the subject and the observer. Three of the human sense organs --- the eyes, ears and nose --- are remote sensing instruments, though remote sensing more commonly refers to the quantitative observation of objects on the Earth, in a geospatial context, using technology designed for this purpose. Remote sensing instruments are typically mounted on air- or spacecraft, though they can just as easily be handheld or tripod-mounted. Such instruments might include a spectrometer for measuring the electromagnetic reflectance of an object or a laser rangefinder scanner (LiDAR) for describing its structure in three dimensions. Satellite and airborne remote sensing have many use-cases, from tracking sea ice extent \cite{Dierking2006,Shuchman2004}, to estimating standing timber volumes \cite{Allouis2011,Tonolli2011}, to investigating plant health at the scale of a single leaf \cite{Palou2013}.

The scale of the phenomenon under investigation, in part, determines the distance from the instrument to the subject. Sea ice, for example, must be observed at a hemispheric scale from a high-orbit satellite, while a study of the fine structure of individual plants must be performed at a much smaller remove. A large resolution of 25m-1000m \cite{Shuchman2004} might be suitable for the study of Arctic ice extent while 5cm or less \cite{Palou2013} would be appropriate for the study of plant health at the leaf level. 

The subject distance has a deterministic relationship with the resolution of a given instrument, where resoluton is defined as the minimum size of object that can be discriminated. If an object is larger than the resolution of an individual element in a spectrometer, that element's specta will be pure --- they will not be contaminated by those of surrounding objects. If, on the other hand, the object is smaller than the instrument's resolution, the spectra will be mixed. This hampers the researcher's ability to accurately identify objects in the image \cite{Lillesand1999}. In the case of point data, such as that produced by LiDAR, increasing the subject distance reduces the point density which, in turn, reduces the number of points associated with an object of interest. In this case, the power of any statistical analysis of points related to that object is reduced. 

The resolution of an instrument is determined by its instantaneous field of view (IFOV), that is the solid angle around the instrument's measurement axis, within which it is sensitive to incoming information \cite{Lillesand1999}. Resolution, subject distance and IFOV are related by the identity, 

\begin{equation}
r = d \theta
\label{eq:ifov}
\end{equation} 
where $r$ and $d$ are the resolution and distance linear units and $\theta$ is the IFOV in radians \cite{Lillesand1999}. A similar relation exists between platform elevation and the point density of a LiDAR instrument, where the scan angle is analogous to the IFOV. 

A side effect of the relation in eq. \ref{eq:ifov} is that changes in the subject distance induce along track (for a moving instrument) scale distortion in the image. As an example, figure \ref{fig:scale_cam} shows a nadir-aligned camera with the black object twice as far from the instrument as the white object. In the image view (figure \ref{fig:scale_img}), the nearer object appears twice as large --- and therefore twice as detailed --- as the far one. 

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/scale_topography_cam.pdf_tex}
\caption{Side view of nadir-aligned camera with subjects.}
\label{fig:scale_cam}
\end{figure}

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/scale_topography_img.pdf_tex}
\caption{Resulting image with scale distortion.}
\label{fig:scale_img}
\end{figure}

It is clear that subject distance and, therefore, platform elevation, in the case of airborne instruments, have important effects on the quality of remotely-sensed data. It follows that, in the interest in maintaining the resolution and point density of remotely-sensed data, it is necessary to control the elevation of an airborne platform to account for variation in the surface elevation, particularly at lower elevations and smaller scales, where such variations have a relatively larger effect. In the case of unmanned aerial vehicles (UAVs), where the pilot is not with the vehicle and cannot monitor and control its elevation with sufficient accuracy, this must be automated. This ability is called terrain-following (figure \ref{fig:uav_terrain}).

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/uav_terrain.pdf_tex}
\caption{Terrain-following UAV.}
\label{fig:uav_terrain}
\end{figure}

The current explosion in interest in UAVs for everything from home delivery to remote sensing to toys to military applications, has made compact UAVs more accessible to researchers than previously. Commercial-grade UAVs with payload capacities of over 6kg are now common, and at reasonable prices. However the use of UAVs for scienctific purposes, though growing, is still fairly new and use-appropriate control systems are a field of rapid development. For remote sensing applications, the need for accurate terrain following systems is being felt. Terrain following contributes not only to the safety of the vehicle and people, animals and property within the study area, but has a profound influence on the quality of data as explained previously. 

UAVs offer many advantages over traditional, manned aerial platforms. First among these is cost. Fixed-wing and rotary surveys may cost thousands of dollars per flight-hour. The instrumentation required for such surveys may cost hundreds of thousands or millions  of dollars. Flight planning and execution of a UAV survey can be accomplished rapidly, and changes to a flight plan do not represent a significant delay or expense. A UAV survey need not originate at an airport. The training required to operate a UAV in accordance with federal regulations, while substantial, is trivial in comparison to pilot training and certification, and a UAV pilot need not be dedicated to the profession. Most importantly, the low platform elevation of a UAV survey radically increases the attainable resolution for raster products and point density for LiDAR products.

Coincidentally, there is a simultaneous explosion of interest robotics, and especially autonomous automobiles, which has encouraged numerous companies to rush to market with compact LiDAR devices of various types \cite{Quanergy2017,Dormehl2017,Morin2017}. These devices are designed to be light, durable and affordable and are meant to give robots and cars the ability to sense their surroundings in three dimensions, in order to navigate safely through their environment. They happen to be ideal (at least in form and cost) for use on UAVs, both for remote sensing applications, and for autonomous vehicle control.

Unfortunately, the state of the art in battery technology is not adequate to the power requirements of heavily-laden remote-sensing UAVs. The overuse of battery resources entails significant costs in terms of mission turn-around time and expense, in terms of the number of flights required to cover a study area and the number of sets of batteries required to complete a mission. The extra mass and power draw of extra rangefinders for terrain following exacerbates this problem.

These issues motivate the present research and the questions:

\textbf{For a remote sensing unmanned aerial vehicle,
\begin{enumerate}
\item what type and arrangement of laser rangefinder instrument(s) is best suited to the task of real-time terrain following, and;
\item what is the optimal vertical trajectory function, in terms of the stability of resolution and point density, the safety of the platform, and the conservation of on-board power?
\end{enumerate}}

Obtaining and testing all of the available --- and not-yet available --- laser rangefinders would be costly and time-consuming. This project will attempt to design computerized simulations of a variety of instruments and configurations by sampling from a variety of modelled surfaces. Such surfaces can be represented by mathematical models, such as planes and unions of geometric shapes, or collected from the real world by LiDAR devices. The sampling pattern and density will be modified to resemble the output of various laser rangefinders, and noise will be added to simulate the instruments' error charactristics. An important benefit of simlation is the ability to eliminate environmental factors and isolate the true benefits of one system over the other.

This research will be concerned with optimizing data quality for two types of instruments, a hyperspectral push-broom scanner, and a scanning LiDAR, and will attempt to quantify the distortions induced in each by the chosen terrain-following strategy. Ultimately, a multi-rotor UAV will be outfitted according to the results of the simulation for testing.


\section{Background}

\subsection{LiDAR}

Light detection and ranging (LiDAR) is a relatively new technology which uses laser pulses to measure the distance from the instrument to a surface. The typical LiDAR-equipped vehicle will use the global positioning system (GPS) for geodetic positioning, an inertial navigation system (INS) for measuring the inertial moments (attitude, angular velocity), a highly accurate clock, a computer and the laser instrument itself \cite{May2007,Lillesand1999}. LiDAR is considered an "active" sensor, as it provides its own source of energy. LiDAR works by sending out a pulse of laser light towards an object and recording the reflection of the pulse. The clock determines the time-of-return of the pulse, which then is used to calculate the distance that the pulse has travelled. The INS and GPS are then used to convert the polar coordinate of the relfector to a the three-dimensional coordinate in Cartesian space, given the known orientation of the vehicle and the fixed position of the laser. 

The laser itself may take many forms. Some LiDAR devices consist of a single, fixed laser while most consist of a single laser with a spinning or oscillating mirror that creates a linear scan pattern of repeated pusles. In the latter case, the computer has information about the orientation of the mirror and can accurately compute the position of the reflector based on this angle and the range. Recently, LiDAR devices have appeared for the autonomous vehicle market which feature multiple beams fixed to a spinning rotor. These differ from the spinning mirror type in that, with every revolution, they create multiple scan lines. Used in airborne applications, this enables re-sampling of the subject as the vehicle moves, and may result in a very high-density point cloud. The autonomous vehicle market places a premium on cost, simplicity and reliability, which has led to the proliferation of solid-state LiDAR devices. Unlike devices with rotating components, solid-state LiDARs have no moving parts and are much less likely to suffer a mechanical failure. These have the side-benefit that they are cheaper to manufacture and potentially much smaller and lighter than mechanical devices. Solid state LiDARs are available in single- and multi-beam configurations using multiple emitters, or a single emitter with a splitter.

The pulses emitted by the laser are not instantaneous, but consist of waves of light of stable intensity. The LiDAR's receiver reads the returning pulse as a waveform of time versus intensity. It discretizes this waveform and extracts the peaks as individual returns. This enables the device to extract more than one return from a single pulse. The "footprint" of a laser is not infinitely small, but tends to spread with distance. In complex environments, with multiple reflectors along the path of the laser, such as the leaves of a tree, the LiDAR may register returns from the top of the canopy, the ground and from intermediate obstructions. Some LiDAR devices record as many as five returns per pulse \cite{Lillesand1999}.

There are several measures of data quality for LiDAR data, including relative and abolute vertical and horizontal accuracy and point density. Positional accuracy may be degraded by numerous factors including platform position and attitude errors, boresight misalignment, range measurement error, scan angle error and beam divergence error \cite{May2007}, however this is somewhat beyond the scope of this project. Point density represents the number of points that can be found within a unit of continuous space, commonly described by a two-dimensional grid. Because a LiDAR instrument emits a fixed number of pulses per unit time, and because the instrument-to-target distance is proportional to the coverage area, it is clear that point density at nadir declines with elevation. 

As a LiDAR-equipped aircraft follows a flight line, a scanning LiDAR scans across the track. The pulses emitted by the instrument strike a flat surface at $90\degree$ at nadir, and at increasing oblique angles towards the ends of the scan line. The obliqueness of these angles has several consequences. First, a pulse striking a target at such an angle is likely to reflect away from the instrument, rather than back towards it; second, the increased distance that the pulse must travel increases the magnitude of the error inherent in the measurement (which is then inconsistent with the error at nadir); third, the pulse is striking the subject from the side, rather than the top, as intended. These issues are exacerbated when the platform's roll angle is non-zero. It is therefore common to filter out points within a certain distance of the flight line edge. The removal of edge points is compensated for, to some degree, by flying parallel lines with substantial overlap, up to 50\%. With this amount of overlap, every subject is effectively scanned twice. The consistency of this overlap is dependent on the consistency of the platform elevation and roll angle.

A further density-related issue is the role that platform pitch plays in the variability of point density. If the platform accelerates in the forward direction, it will pitch forward slightly, angling the scanner towards the aft, creating a region of increased point density. However, if the vehicle slows, it will pitch rearward, creating a region of reduced density. Clearly it is desireable to minimize variations in platform pitch.

Point density has scale-determined implications for research. If a researcher is attempting to describe the canopy structure of 90m-tall old-growth forests, the platform elevation must be sufficient for the mission to encompass a significant number of crowns in a reasonable amount of time and to  minimize the variance in nominal point density between the ground and the tree top. The point density required for the study of such enormous plants is much lower than that required for a single grape vine, where a researcher may be interested in the orientation of individual leaves. To characterize the structure of a grape vine, point density must be suitably high, which, using the same instrument as used for the old growth, requires a lower flight elevation. However, if the vinyard is situated in a valley with considerable relief, the variance in point cloud density at a constant geodetic elevation will reduce the point density in lower-elevation sectors of the study area. This effect is proportionally larger at lower elevations.

It is important to note, here, the distinction between terrain elevation and surface elevation. A study using LiDAR may be concerned with the morphology of the terrain itself, or with objects on the terrain, such as plants and buildings. Whether the instrument's elevation follows the terrain, or the surface, which includes such objects, is decided by the purpose of the campaign. If the goal is to study objects on the terrain, it is usually desireable to maintain the platform's elevation with respect to the surface elevation, for example a forest canopy. If the subject of study is the terrain itself, the elevation should be maintained relative to it. The latter case introduces the problem of obstacle avoidance and object identification. For example, it must be determined whether an increase in terrain elevation is due to the appearance of a vegetative canopy or an actual up-slope in the terrain. If the former is true, and the platform is following the terrain elevation, it must be configured to avoid colliding with the trees.

Point density and flight-line overlap are manageable, then, so long as the variation in platform elevation relative to the subject is minimized. There are two ways to accomplish this: First, by rasing the platform to a sufficient elevation to minimize the variation in point density; second, by following the terrain at a constant relative elevation. This research is concerned with the latter option.

\subsection{Hyperspectral Imaging}

A hyperspectral sensor, or imaging spectrometer, is a passive sensor that measures reflected light in very narrow frequency bands. Some such scanners can record over 400 distinct spectra. There are two primary types of hyperspectral sensor, the push-broom scanner, which is an array of sensor elements oriented across the scanning direction, and the whisk-broom scanner, in which an array of elements aligned with the scanning direction sweeps side-to-side across it \cite{Lillesand1999}.

The advantage of a hyperspectral scanner over a multi-spectral scanner, such as the Landsat Thematic Mapper, is the narrow width of its spectral bands. For example, band 7 of the Landsat TM instrument is $0.27\si{\um}$, while a typical hyperspectral scanner will record bands of $0.01\si{\um}$ in width \cite{Lillesand1999}. Just as a high spatial resolution reduces the mixing of spectra in a pixel, a high spectral resolution reduces mixing within spectra. If, for example, there is an absorbtion feature somewhere within Landsat's band 7, it will be impossible to discern. A collection of narrower  bands across the same span of wavelengths will be able to resolve the feature.

A major issue with all spectrometers is the interaction between light and the atmosphere. The ultimate goal of spectometry is to determine the reflectance of a surface, which is presumed to correlate with some characteristic of or process within the underlying object. In a vacuum, reflectance is simply the ratio between irradiance (energy from the source) and radiance (energy reflected from the subject). However, under natural conditions, the spectrometer measures radiance from the subject plus enery reflected from the atmosphere between the sensor and the target (path radiance). Irradiance is then the sum of attenuated light sources, generally the sun and incident radiation from the atmosphere \cite{Lillesand1999}. Unfortunately, these atmospheric effects cannot be ignored, even at the low elevations flown by UAVs. However, the variations can be minimized by maintaining a constant elevation and thus a consistent volume of atmosphere between the sensor and the subject.

Platform elevation has several effects on hyperspectral data quality aside from atmospheric effects. The first of these is the effect on resolution, as discussed above: As the platform elevation increases, the sensor's spatial resolution -- that is, its ability to resolve discrete objects -- declines, resulting in spectral mixing within pixels. Another effect is on the ratio of signal to noise. Each element of a hyperspectral scanner captures a discrete value by recording incoming radiation for a specified interval, called the intergration time. For a given platform velocity and integration time (which are set during the planning phase of the mission), the amount of energy received by an element is proportional to the area of visible reflective surface, which is in turn proportional to the platform's elevation. Since the instrument noise is constant, the reduced proportion of incoming energy reduces the signal-to-noise ratio. In order to maintain this ratio despite variations in elevation, the platform must either adjust its speed, which has other undesireable consequences, or the sensor's integration time, which is not possible or desireable in real time. The integration time has consequences with respect to vehicle velocity as well. When the sensor is active, it smears across the target for the duration of its integration time. So long as the velocity is constant and pitching movements are minimized, this effect is constant.

\subsection{Terrain Following}

The quality issues highlighted in previous sections can be addressed, to an extent, through careful control of the airborne platform by maintaining a constant elevation relative to the target and minimizing the axial movements of the platform. However, unlike a fixed-wing aircaft and helicopters, which maintain the attitudes of their chassis using control surfaces and tilting rotors, respectively, a mutli-rotor UAV moves by coordinating the differential thrust of its fixed rotors and modifying its attitude. This poses a unique challenge for the autonomous control of UAVs used in remote sensing. It must also be noted that a remote-sensing UAV should not take lateral evasive action unless absolutely necessary; it must follow its flight plan to ensure that the entire target area is sampled.

When a UAV encounters a change in surface elevation it must adjust its trajectory. Due to the inertia of the platform, the change in velocity is  necessarily delayed until some time after the vehicle's thrust and attitude have been adjusted. It is thus impossible for a vehicle to follow a terrain exactly using a purely reactive system without backtracking. This situation pertains when the vehicle's rangefinder is oriented to nadir. Trivially, if the vehicle approaches a vertical face and is not capable of sensing forward, it will contact the face. Alternatively, the vehicle may have the ability to sense changes in surface elevation some distance ahead in the direction of travel. Should it encounter a vertical face, it can take evasive action.

In the naive case, the vehicle's horizontal velocity must drop from the nominal flight velocity to zero and its vertical velocity must increase from zero. This is undesireable in a remote sensing context as, during the deceleration, the sampling density will increase until, during the ascent, the instruments will continue to sample the same ground repeatedly as the horizontal velocity has dropped to zero. After the ascent, there will be a brief flight over a surface at the original elevation while the vehicle is at the new elevation. Scale distortion in this region will be maximized. Also at this time, the vehicle will begin accelerating in the horizontal direction again, with gradually-decreasing under-sampling over the elevated surface. These anomalies will have to be rectified in post-processing, if possible. Alternatively, the vehicle can follow a smoothed trajectory which departs from the nominal flight elevation but preserves the vehicle's horizontal velocity (figure \ref{fig:uav_smooth_traj}). In this case, scale distortion is induced in the data, but the along-track sampling density remains constant. In either case, the vehicle must anticipate the change in elevation in order to successfully follow the surface without contacting it or backtracking over ground that has already been sampled.

There are mechanisms for enabling terrain following for UAVs which depend on the pre-existence of a digital surface model (DSM). This has two consequences: first, that the survey must have been performed previously and the resulting data processed into a DSM; second, that the DSM must be of sufficient quality, accuracy and detail to control the UAV safely, given the nature of the terrain, ground cover and the desired flight elevation. Currently-available solutions use the Shuttle Radar Topography Mission (STRM) elevation model, which is one of few freely-accessible global DEMs, but is not a true DSM: C-band RADAR may penetrate up to half way into a forest canopy \cite{Carabajal2005} and will penetrate into snow, depending on its porosity and wetness \cite{Tighe2009}. The maximum resolution of the SRTM DEM is $30'$ (approximately $30\si{\m}$) horizontally and $1\si{\m}$ vertically, with stated vertical accuracy of $\leq16\si{\m}$, much too large for low-elevation remote sensing work, particularly in steep or forested terrain.

An ideal solution would be for the UAV to compute a terrain model on its own, in real time, and follow the terrain at a fixed elevation while executing its flight plan. The system provides an opportunity to implement obstacle avoidance: objects that are identified as non-ground, yet obstruct UAV’s trajectory may be used to signal a return-to-home response, or a go-around plan and, depending on the uncertainty inherent in the instrument, the point cloud generated by a forward-facing laser may be contributed to that of the downward-facing main LiDAR, both to densify it and to contribute views of the subject from fore and aft, rather than only left and right, as is typical. 


\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/uav_smooth_trajectory.pdf_tex}
\caption{Zero-velocity and smoothed trajectory adjustments. Black arrows indicate regions of scale distortion. Dashed arrows indicate regions of over-sampling due to changes in horizontal velocity.}
\label{fig:uav_smooth_traj}
\end{figure}

The problem of platform stability during elevation adjustments is complex. A hovering UAV requires an amount of thrust (measured in Newtons, $N$) equal to the downward force on the vehicle, given by

\begin{equation}
f = ma
\label{eq:hover_force}
\end{equation}, where $f$ is the downwad force, also in Newtons, $m$ is the mass of the vehicle in kg, and $a$ is the acceleration of gravity on Earth, approximately $9.8m/s^2$. A UAV moving forward at a steady velocity requires an amount of thrust equal to the hovering thrust plus an additional force to maintain altitude while it moves horizontally. This is given by,

\begin{equation}
v_i = \dfrac{ v_h^2 } { \sqrt{ (v_\infty \cos \alpha)^2 + (v_\infty \sin \alpha + v_i)^2 } } 
\label{eq:move_force}
\end{equation}, where $\alpha$ is the angle of attack, $v_\infty$ is the free stream speed (platform velocity plus wind) and $v_h$ is the hover velocity \cite{Hoffmann2007}. If the maximum available thrust of the platform is known, this provides an approximate limit on the rate of climb acheivable by the vehicle, which, in turn, places limits on the amount of advance warning required by the vehicle for a given change in elevation.

\iffalse
As an example, for a UAV weighing $10\si{\kg}$ flying at $5\si{\m\per\s}$, the distance required to climb $1\si{\m}$ is,

\begin{equation}
v_i = \dfrac{ v_h^2 } { \sqrt{ (v_\infty \cos \alpha)^2 + (v_\infty \sin \alpha + v_i)^2 } } 
\label{eq:move_exple}
\end{equation}.
\fi

With a forward-facing rangefinder, the problem of an approaching obstacle is easily resolved, but descending presents another problem. As the vehicle approaches the lip of a cliff, the terrain below the face is occluded by its edge (figure \ref{fig:uav_edge_occlude}), depriving the vehicle of elevation information that it needs to optimize its trajectory. With a single-beam rangefinder, at one timestep, the lip will be sampled, and at the next, the ground will be sampled. The vehicle can estimate the terrain as the convex hull of these elevations, and derive a trajectory based on this modelled terrain, but it cannot revise this estimate or its trajectory without a rangefinder with a broader vertical field of view, or one or more additional ragefinders directed downward at a steeper angle. A similar phenomenon occurs when the vehicle is traversing down a slope that does not intersect with the rangefinder's beam. If the end of the slope is beyond the instrument's range, the vehicle loses contact with the ground and has no information from which to compute a trajectory.  Ideally, the vehicle could have a sensor that is sensitive from nadir to the horizon, and adjust its trajectory iteratively as it approaches the edge. 

To identify a sufficient advance angle for a forward-facing rangefinder, it is necessary to first calculate the time reqired for a UAV to change its velocity. At the extreme, in the case of the vertical cliff of indeterminate height, this is the time required to reduce the vehicle's horizontal velocity to zero. It would be a simple matter to calculate the time required for the vehicle to decelerate given its mass, available thrust, velocity and environmental conditions. However, owing to the fact that a multi-copter must control its speed by pitching, which should be minimized to protect data quality, the rate of deceleration should be carefully considered. On the other hand, if the horizontal distance dedicated to ascending is to be minimized (to minimize the horizontal distance affected by scale distortion), the vehicle's maximum thrust must be considered --- it must be able to ascend rapidly enough to clear the terrain without losing horizontal velocity.

Possibilities

The vehicle faces a vertical cliff so high its horizontal v drops to zero.
The vehicle encounters a slope and increases its power enough to climb without losing horizontal velocity.


Research into terrain following has been continuing since the 1960s for the control of ballistic missiles and jet aircraft \cite{KRACHMALNICK1968,Starling1971,Cunningham1980}. Such systems use a forward- and downward-facing RADAR rangefinder to detect the terrain elevation some distance ahead of the vehicle, some means of terrain classification \cite{Cunningham1980}, and a method of altering the vehicle's trajectory to follow the terrain surface as closely as possible. Research on terrain following for military aircraft and missiles has been focused on high-speed, low elevation flight with a premium placed on stealth, speed, efficiency and safety \cite{KRACHMALNICK1968}. It is important to note the distinction between terrain following and terrain avoidance, here: terrain avoidance involves changing the trajectory of the vehicle, vertically or horizontally, in order to avoid terrain; terrain following implies the maintenance of a minimum distance to the terrain, but also a maximum distance. Missiles and military aircraft must fly low to avoid detection by radar and interception by surface-to-air or airborne weapons. Neither high speed nor stealth are desireable for a remote sensing mission but many of the insights from this research are nevertheless applicable to remote-sensing UAVs.

The key feature of these terrain following systems is their predictive, rather than reactive, nature. Most existing UAV terrain following systems use either a nadir-aligned rangefinder and a feedback loop for adjusting the vehicle's elevation to a predetermined value in real time \cite{ArduPilot2017}, or a pre-exiting elevation model which is interpolated to generate a three dimensional flight path \cite{ArduPilot2017,Samar2011}. Military terrain following systems provide both the ability to adaptively respond to terrain without pre-planning, and the ability to optimize their flight plans in flight with some degree of foresight. 

For example, Starling \cite{Starling1971} envisioned a RADAR-based system featuring a virtual "ski" sliding on the terrain ahead of, and in alignment with, the aircraft. As the ski encountered a rise, its axis would intersect that of the aircraft, generating a climb-command, causing the aircraft to climb. As the ski rode the terrain down again, the axes of the aircraft and the ski would diverge, generating a descend-command. This feature had the valueable quality that on low-frequency terrain, the aircraft would follow it closely. On high-frequency terrain, the aircraft woud tend to smooth the terrain, following a trajectory that would not exceed the gravitational tolerances of the pilot (about 1g). Several authors (\cite{MENON1991,Popovic2017,Lu1995,Rahim2011,Samar2011}) suggest the use of polynomial splines for developing smoothed trajectories from terrain elevations, and Lu and Pierson \cite{Lu1995} documented a method for terrain-following in a fixed-wing aircraft by exploiting the lift and drag properties of the vehicle and "bang-bang" (on/off) throttle control. 

None of these strategies are ideal for remote sensing UAVs. In the first and second instances, maintaining a constant elevation with respect to terrain immediately below the vehicle is not the rsearchers' primary concern. In the third, reliance on the aerodynamic lift of the craft to smooth elevation changes in a power-off situation is a non-starter, as multi-copters have essentially none.

Alqahtani and Emron \cite{Alqahtani2018} devised a system using using downward- and forward-facing single-beam rangefinders and a Gaussian surface filter with various window sizes to anticipate terrain undulations and project a forward trajectory for terrain avoidance. This system is attractive for remote sensing applications because, unlike the military vehicle terrain-following strategies, it minimizes the overshoot on descents. Gaussian filtering is desireable also because it can be rapidly computed in a raster context in one or two dimensions. 

\begin{figure}
\centering
\def\svgscale{0.8}
\input{build/images/uav_edge_occlude.pdf_tex}
\caption{Rangefinder occlusion on obstacle edge.}
\label{fig:uav_edge_occlude}
\end{figure}

The use of a full, 3-dimensional point cloud and ground classification algorithms have not been studied for the purpose of terrain following, perhaps because the LiDAR devices small enough for use on such vehicles are a recent innovation. The optimization of trajectory functions for data quality maintenance and power conservation have also not appeared in the literature. 


*** The power required by the vehicle following any trajectory can be calculated by taking the integral of the function decribing the thrust or power curve. This curve will be something like figure \ref{fig:uav_power_curve}.


\begin{equation}
T_d = \dfrac{v}{\sin(\theta) * E}
\label{eq:decel}
\end{equation} 

\begin{figure}
\centering
\def\svgscale{0.8}
\input{build/images/uav_power_curve.pdf_tex}
\caption{The power curve of a terrain-following event.}
\label{fig:uav_power_curve}
\end{figure}


\subsection{Rangefinder and Algorithm Selection}

There are several choices in instruments and algorithms that will be made in the course of this research, firstly, in terms of rangefinder instrumentation.

A digital RGB camera with a wide-angle lens will cover the desired field of view at high resolution and low cost, but will require computationally-intensive photogrammetric or optical-flow processing to extract range measurements. These methods work only when the platform velocity is sufficient to induce detectable changes in the pixel array. Also, spectrometers are passive sensors, meaning they record reflected light from variable environmental sources, specifically the sun and are thus subject to weather conditions and the availability of daylight. Tracking changes in intensity or colour across the pixel array becomes difficult without the consistency of a controlled energy source, or on low-contrast surfaces, hampering the detection of objects which would be used to compute ranges. Finally, neither photogrammetry or optical-flow provide the level of canopy penetration that laser instrument can.

One or more single-beam laser range finders can be mounted statically, on a scanning gimbal or in a mixture of configurations. Laser rangefinders are active scanners that emit laser pulses and measure the time of return from a subject to compute the subject distance. Environmental conditions and scene contrast are not likely to affect measurement accuracy, however point density reduced by scattering, absorbtion or reflection on some surfaces, such as water. These rangefinders are cheap and light but do not offer the spatial coverage of either a digital camera or a scanning LiDAR, making the intelligent analysis of terrain conditions difficult.

Scanning LiDAR devices --- whether spinning or oscillating mirror type, rotating single- or multi-beam or solid state --- provide the most complete coverage of a surface and enable the most comprehensive analysis of the surface. These have the drawback that they are heavier than other options,  consume more power, and produce a high enough volume of data that processing can be complex and time consuming, but they resolve most of the problems inherent in digital cameras and single-beam rangefinders.

With the advent of automotive multi-beam scanning LiDAR devices, a unique opportunity arises. Unlike traditional scanning LiDARs, these devices produce multiple, simultaneous scan-lines over an arc from $30\degree$ to $40\degree$. By tilting these instruments slightly forward, they can serve as both the main remote sensing instrument, and the the terrain following sensor, and can provide sufficient point density and coverage for extremely accurate real-time terrain characterization. For a vehicle flying at 35m elevation, a LiDAR scanning $30\degree$ forward offers approximately $20\si{\m}$ of advance coverage, or $4\si{\s}$ at $5\si{\m\per\s}$. 

[This would be sufficient for clearing a wall of x m high without reducing horizontal velocity, etc. etc]

[Hyperbolic point pattern]

The data produced by the rangefinder must be processed for several purposes. 

If a photo-flow or photogrammetric solution is selected, the imagery generated by the camera must be processed in real time to produce a three-dimensional model of the environment, from which ranges can be extracted.

If one or more single-beam rangefinders are chosen, there is not much processing, unless one or more of them is mounted on a scanning servo.

If a scanning LiDAR is used, either separately or the main instrument, there are many more opportunities to derive useful navigational cues, such as the identification of vegetation vs. terrain (for terrain surveys), the distinction between small obstacles and slopes, side-views while turning.

Once an accurate picture of the surface elevations is derived, the flight controller must decide what to do and when to do it. This includes calculating the ideal trajectory given the current state of knowledge of the surface and the dynamic constraints on the platform.


\iffalse


\subsection{SLAM}

Simultaneous localization and mapping.

Traditional terrain-following mechanisms used RADAR for measuring the distance from aircraft to terrain. The advent of cheap, lightweight LiDAR instruments, primarily designed for the autonomous vehicle market, has made available 


The Kalman Filter \cite{Kalman1960} is a recursive least-squares optimizing function that effectively converges on a true value -- in one or more dimensions -- at each time step by assigning a weight to the current state and the inputs depending on the confidence in each, and generating a new state estimate which will be subjected to the same process on the next time step. A primary consideration in the development of state-space smoothing methods such as Kalman's is the impossibility of storing a complete history of the object's state and estimating its immediate future based on its entire past. The latter would entail an ever-increasing processing load, as the object's history grew. Another consideration is the temporal variability in the certainty of new estimates of the object's state (i.e. measurements). As these vary through time, they would also have to be stored and computed to derive an estimate of the object's state. The Kalman filter solves these problems by considering only the object's present state, the inputs, and an error estimate for each \cite{Swerling1959}. 

Kalman filtering was originally used for estimating the trajectories of the Apollo lunar landers and for RADAR tracking of targets \cite{Grewal2010}, but is widely used in climate science, econometrics, engineering, especially in the field of robotics. Autonomous robots, UAVs included, must have reliable information their position, orientation and velocity in order to interac effectively with the environment. Airborne vehicles, in particular, must have accurate information about their position and orientation, but also their trajectory.

A typical UAV uses the Global Positioning System (GPS) for absolute positioning and an inertial navigation system (INS) for measuring acceleration and orientation. These inputs together allow the vehicle to ajust its attitude and velocity to maintain a pre-defined trajectory, and -- arguably, more importantly -- for georeferencing collected data. There are numerous sources of measurement error inherent in GPS and INS measurements which hamper the vehicle's ability to ascertain its instantaneous state; the Kalman filter provides a means of determining its true state with a high degree of confidence.

[Extended Kalman filter -- local linearization?]

\fi

\subsection{Mission Planning}


For remote sensing surveys using UAVs, missions are generally not flown manually by the pilot, but planned using software that lays out a regular grid of flightlines optimised for data resolution and flight line overlap. However, these mission plans are two-dimensional only, and must be augmented by an auxiliary terrain-following process.

One such software product is Maps Made Easy, which produces flight plans for popular UAVs made by the DJI company. 


\subsection{Ground Classification}

Single-beam vs. multi-beam.

Multi-element vs. planar. \cite{Nobili2015}


In cases where the researcher is concerned with vegetation or human-made structures, a UAV will generally be required to follow the surface elevation. In the case of forest or agricultural research, this will be the vegetative canopy, while in the case of structures, this will simply be a safe elevation. For surveys of the underlying terrain, some kind of ground classification must occur --- the vehicle must be able to distinguish between object on the terrain (which will be filtered out in post-processing) and the terrain itself. At the same time, the vehicle must maintain the ability to reconize the existence of object which are higher than its flight elevation, and react accordinly.

The technology for automating ground classification is not mature \cite{Vosselman2001,Vosselman2000} and perfection is, of course, not possible. But what are the implications for UAV control, but there are several methods for the identification of terrain features. The simplest of these is to take the last return from every pulse, as this represents the most distant surface from the platform --- the ground.

The point density of the instrument is likely to be limited, as is the capability of processing the full cloud. A higher density is better for classification, but instrument noise and vegetation present serious issues. What if the point cloud cannot penetrate into the canopy? The drone may have some way of reconciling a naive assumption about the nature of the terrain, and the information is receiving from the scanner?


\subsection{Simulation}

Given the variety of laser scanner types and configurations, and the variety of terrain and ground-cover types a UAV may encounter, it is prudent to attempt to simulate and assess a variety of virtual instruments and conditions before purchasing hardware. Several rangefinder configurations are listed in figure \ref{list:rangefinder_configs}.

\begin{itemize}
\item Single-beam, single-return.
\item Single-beam, multi-return.
\item Single-beam, single-return with a servo driver for mechanical, side-to-side scanning.
\item Split-beam, multi-return, solid-state.
\item Multi-beam, multi-return, solid-state.
\item single-beam, multi-return, spinning laser.
\item Multi-beam, multi-return, spinning laser.
\item Multi-beam, multi-return, spinning mirror.
%% \caption{Laser rangefinder configurations.}
\label{list:rangefinder_configs}
\end{itemize}

It must also be determined which sampling method is optimal. A static single-beam range finder will produce a series of points in a line along trajectory of the platform. This may be sufficient to detect the surface elevation directly in front of the platform, but may not be robust to noise, may not enable the detection of ground returns, and will not produce a useful side-view when the vehicle is turning. Single-beam lasers are cheap and lightweight, which reduces the load on the platform's power supply. A fan-shaped scanning pattern would produce a 3-dimensional point cloud which would enable ground point filtering, some noise removal and limited side-looking ability in turns. These instruments are more costly and heavier, but may be able to contribute to improved data quality and platform safety. Single-beam rangefinders may be mounted statically or on a servo, which scans back and forth across the terrain in a sinusoidal fasion (figure \ref{fig:sinus_plane}).

The output of any rangefinder can be simulated by defining a terrain-generating function and sampling it at positions that would be read by the instrument. Gaussian noise can be applied to the samples simulate measurement error using the characteristics documented by the manufacturer or testing. In a real-world scenario, it would be neccessary to account for uncertainty about the vehicle's elevation and the actual elevation of the terrain. In a simulated environment these can be controlled, leaving only the optimality of the trajectory to be assessed.

Figure \ref{fig:point_plane} shows an example of the output of a hypothetical regular sampling of a planar surface. The first plot shows the outcome using measurements with zero uncertainty. In the second and third images, the measurements are perturbed by random Gaussian noise with standard deviations of 0.001 and 0.01, respectively, to simulate error.

\begin{figure}
\centering
\def\svgscale{0.25}
\input{build/images/plane_grid_0.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_grid_0001.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_grid_001.pdf_tex}
\caption{Simulated grid sampling of planar surface with Gaussian error; $\sigma 0$, $\sigma 0.01$ and $\sigma 0.001$.}
\label{fig:point_plane}
\end{figure}


Figure \ref{fig:sinus_plane} shows the result when the planar model is scanned in a sinusoidal fasion by a servo-mounted rangefinder.

\begin{figure}
\centering
\def\svgscale{0.25}
\input{build/images/plane_sinus_0.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_sinus_0001.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_sinus_001.pdf_tex}
\caption{Simulated sinusoidal scan of planar surface with Gaussian error; $\sigma 0$, $\sigma 0.01$ and $\sigma 0.001$.}
\label{fig:sinus_plane}
\end{figure}


Figure \ref{fig:linear_plane} shows the result when the planar model is scanned in a linear fasion by a statically-mounted rangefinder.

\begin{figure}
\centering
\def\svgscale{0.25}
\input{build/images/plane_linear_0.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_linear_0001.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_linear_001.pdf_tex}
\caption{Simulated linear scan of planar surface with Gaussian error; $\sigma 0$, $\sigma 0.01$ and $\sigma 0.001$.}
\label{fig:linear_plane}
\end{figure}

Figure \ref{fig:plane_object} shows the result of scanning a plane with a square object using a grid, sinusoidal scan and linear scan.

\begin{figure}
\centering
\def\svgscale{0.25}
\input{build/images/block_grid_0.pdf_tex}
\def\svgscale{0.25}
\input{build/images/block_sinus_0.pdf_tex}
\def\svgscale{0.25}
\input{build/images/block_linear_0.pdf_tex}
\caption{Simulated scans of planar surface with obstacle.}
\label{fig:plane_object}
\end{figure}


Any rangefinder configuration

of these can be simulated by reading an existing real-world or generated point cloud, applying parametric noise and densification, and streaming the points into the navigation system as if they were being produced at flight time by a rangefinder. If a real-world point cloud is used, the measurement error inherent in the original product may be maintained or increased, and it may be densified using the documented nominal uncertainty for the campaign. A modeled terrain, such as a simple plane or three-dimensional polynomial surface, with or without objstructions, can be sampled at an arbitrary density and the samples perturbed using Brownian or Gaussian noise.

Simulate a variety of terrain conditions: Flat, sloped, undulating, etc. with and without obstacles

Generate simulated point clouds as if from a rangefinder or scanner, single or multibeam.

Add parameterized noise to the simulated measurements to simulate real-world noisy measurements.

Generate noisy vehicle position inputs, etc.

LIDAR ACCURACY \cite{May2007}




\subsection{Control}

Control Loops








** Most (all?) current applications use a nadir laser and reactive paradigm. I want to create a smoothed trajectory with configurable limits (for safety) based on a predictive regime. a) from facing forward, and b) from computing trends based on past measurements.

** Kalman filter. Can be used to compute a trajectory from the vehicle’s current state and inputs from instruments, and flight plan. 



Photogrammetry
Still a possibility

Makers:
Velodyne (solid state lidar coming)
Quanergy (S3)
AEye
Leddar (range sucks; 20m @ 18% grey)

Purpose: Build a system that:

\begin{itemize}
\item Ascertains the vehicle's state using GPS and INS inputs and the Kalman filter.
\item Ascertains the elevation some fixed distance in front of the vehicle using a forward-facing rangefinder; multi- or single-beam TBD; ground classification requirements TBD.
\item Adjusts the 2D trajectory using the vehicle's state and future changes in elevation using some smoothing method (possibly Kalman) as well as insight gleaned from other terrain following methods.
\item Controls the vehicle so that it will follow the trajectory.
\end{itemize}


\bibliographystyle{plain}
\bibliography{/home/rob/Documents/bibtex/library.bib}


\end{document}