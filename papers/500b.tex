%%  Doesn't work... \usepackage{apacite}	% for APA format; requires sudo apt-get install texlive-bibtex-extra

\documentclass[10pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{setspace}	% for line spacing
\usepackage{calc}		% for figure scaling
\usepackage{svg}		% for graphics
\usepackage{graphicx}	% for graphics
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\author{Rob Skelly}
\title{Real-Time Terrain Following and Trajectory Adjustment for Remote-Sensing Unmanned Aerial Vehicles}

% Images are build by calling images/generate.sh <images> <output> where
% output is the "build" directory used by Texmaker.
\graphicspath{{./build/images/}}

\begin{document}

\maketitle

\doublespace

\section{Introduction}

Remote sensing is the art and science of sensing, or measuring, objects without the necessity of direct physical contact between the subject and the observer. Three of the human sense organs --- the eyes, ears and nose --- are remote sensing instruments, though remote sensing more commonly refers to the quantitative observation of objects on the Earth, in a geospatial context, using technology designed for this purpose. Remote sensing instruments are typically mounted on air- or spacecraft, though they can just as easily be handheld or tripod-mounted. Such instruments might include a spectrometer for measuring the electromagnetic reflectance of an object or a laser rangefinder scanner (LiDAR) for describing its structure in three dimensions. Satellite and airborne remote sensing have many use-cases, from tracking sea ice extent \cite{Dierking2006}, to estimating standing timber volumes \cite{Allouis2011,Tonolli2011}, to investigating plant health at the scale of a single leaf \cite{Palou2013}.

The scale of the phenomenon under investigation in part determines the distance from the instrument to the subject. Sea ice, for example, must be observed at a hemispheric scale from a high-orbit satellite, while a study of the fine structure of individual plants must be performed at a much smaller remove. The subject distance has a deterministic relationship with the resolution of a given instrument, where resoluton is defined as minimum the size of object that can be discriminated. A large resolution of 20m might be suitable for the study of Arctic ice extent while 5cm or less \cite{Palou2013} would be appropriate for the study of plant health at the leaf level. 

The resolution of an instrument is determined by its instantaneous field of view (IFOV), that is the solid angle or cone, parallel to the instrument's measurement axis, within which it is sensitive to incoming information. Resolution, subject distance and IFOV are related by the identity, 

\begin{equation}
R = 2 E \tan{(\theta / 2)},
\label{eq:ifov}
\end{equation} 
where $R$ and $E$ are the resolution and elevation in the same units and $\theta$ is the IFOV in radians. A similar relation exists between platform elevation and the point density of a LiDAR instrument, where scan angle is analogous to the IFOV. 

A side effect of the relation in eq. \ref{eq:ifov} is that changes in the subject distance induce scale distortion in the image. As an example, figure \ref{fig:scale_cam} shows a nadir-aligned camera with the black object twice as far from the instrument as the white object. In the image view (figure \ref{fig:scale_img}), the nearer object appears twice as large --- and therefore twice as detailed --- as the far one. This phenomenon also implies increasing scale distortion with distance from nadir: As the subject's distance from the instrument's measurement axis increases, so does the subject distance, hence the scale, which results in a gradient in the resolution across the image.

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/scale_topography_cam.pdf_tex}
\caption{Side view of nadir-aligned camera with subjects.}
\label{fig:scale_cam}
\end{figure}

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/scale_topography_img.pdf_tex}
\caption{Resulting image with scale distortion.}
\label{fig:scale_img}
\end{figure}

It is clear that subject distance and platform elevation, have important effects on the quality of remotely-sensed data. For a spectrometer, whose output is rendered as a regular grid of measurements, elevation determines the resolving power of the instrument and conversely the amount of mixing within each pixel; for LiDAR, elevation determines the acheivable point density and thus the stastical power of any discretization of the sampled space. It is also clear that, in the interest in maintaining the resolution or point density of remotely-sensed data, it is necessary to control the elevation of an airborne platform to account for variation in the terrain elevation, particularly at lower elevations and smaller scales, where such variations have a larger effect. This ability is called terrain-following (Figure \ref{fig:uav_terrain}).

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/uav_terrain.pdf_tex}
\caption{Terrain-following UAV.}
\label{fig:uav_terrain}
\end{figure}

With the current explosion in interest in low-elevation remote-sensing UAVs, the need for accurate terrain following systems is being felt. Terrain following contributes not only to the safety of the vehicle and people, animals and property within the study area, but has a profound influence on the quality of data. Terrain-following systems entail the ability to measure the platform's elevation, an accurate sense of where the vehicle is in geodetic space, and algorithms for identifying the true surface elevation and adjusting the vehicle's trajectory to match it. The need for these systems motivates this research, and the question:


\textbf{For a remote sensing unmanned aerial vehicle with terrain-following capability, what combination of hardware, software and configuration maximizes the quality of data in terms of the stability of resolution and point density?}

This research will simulate the point patterns of a variety of laser rangefinder configurations, with a variety of error characteristics on a variety of modelled terrains. Existing points clouds produced by real campaigns over different terrains will be used to test the efficacy of the solution. Data quality will be inferred from the size of the variance in the subject distance during flight.

Finally, a multi-rotor UAV will be outfitted according to the results of the simulation for testing.

\section{Background}

\subsection{Terrain Following}

Research into terrain following has been continuing since the 1960s for the control of ballistic missiles and jet aircraft \cite{KRACHMALNICK1968,Starling1971,Cunningham1980}. Such systems use a forward- and downward-facing RADAR rangefinder to detect the terrain elevation some distance ahead of the vehicle, some means of terrain classification \cite{Cunningham1980}, and a method of altering the vehicle's trajectory to follow the terrain surface as closely as possible. Research on terrain following for military aircraft and missiles has been focused on high-speed, low elevation flight with a premium placed on stealth, speed, efficiency and safety. Neither high speed nor stealth are desireable for a remote sensing mission but some of the same concerns apply. 

When a UAV encounters a change in terrain elevation it must adjust its trajectory. Due to inertia the change in velocity is  necessarily delayed until some time after the vehicle's thrust and attitude have been adjusted. It is thus impossible for a vehicle to follow a terrain exactly using a purely reactive system without backtracking. As an extreme example, if the vehicle approaches a vertical cliff, its horizontal velocity must drop from the nominal flight velocity to zero and its vertical velocity must change from zero. During the deceleration, the sampling density will increase until, during the ascent, the instruments will continue to sample the same ground repeatedly. After the ascent, there will be a brief flight over terrain that is at the original elevation while the vehicle is at the new elevation. Scale distortion in this region will be maximized. Also at this time, the vehicle will be accellerating in the horizontal direction, causing over-sampling. These anomalies will have to be rectified in post-processing. Alternatively, the vehicle can follow a smoothed trajectory which departs from the nominal flight elevation but preserves some or all of the vehicle's horizontal velocity (figure \ref{fig:uav_smooth_traj}). In this case, scale distortion is induced in the data, but the sampling density remains constant. In either case, the vehicle must anticipate the change in trajectory in order to successfully follow the terrain without contacting the cliff face or reversing over ground that has already been covered.

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/uav_smooth_trajectory.pdf_tex}
\caption{Zero-velocity and smoothed trajectory adjustments. Black arrows indicate regions of scale distortion. Dashed arrows indicate regions of over-sampling due to changes in horizontal velocity.}
\label{fig:uav_smooth_traj}
\end{figure}

With a forward-facing sensor, the problem of an approaching obstacle is easily resolved, but descending presents another problem. As the vehicle approaches the lip of the cliff, the terrain below the face is occluded by its edge (figure \ref{fig:uav_edge_occlude}), depriving the vehicle of elevation information that it needs to optimize its trajectory. With a single-beam rangefinder, at one timestep, the lip will be sampled, and at the next, the ground will be sampled. The vehicle can estimate the terrain as the convex hull of these elevations, and derive a trajectory based on this modelled terrain, but it cannot revise this estimate or its trajectory without a rangefinder with a broader vertical field of view. A similar phenomenon occurs when the vehicle is traversing down a slope that does not intersect with the rangefinder's beam. If the end of the slope is beyond the instrument's range, the vehicle loses contact with the ground and has no information from which to compute a trajectory.  Ideally, the vehicle could have a sensor that is sensitive from nadir to the horizon, and adjust its trajectory iteratively as it approaches the edge. 

This last point reintroduces the discussion of instrument and algorithm selections. 


Use the Velodyne for both terrain following and data acquisition by rotating it forward so that the leading edge points 30 degrees forward and the trailing edge is at nadir. This is probably the best plan.


\begin{figure}
\centering
\def\svgscale{0.8}
\input{build/images/uav_edge_occlude.pdf_tex}
\caption{Rangefinder occlusion on obstacle edge.}
\label{fig:uav_edge_occlude}
\end{figure}

\subsection{Rangefinder and Algorithm Selection}

A spectrometer (i.e., an RGB camera) with a wide-angle lens will cover the desired field of view at high resolution and low cost, but will require computationally-intensive photogrammetric or optical-flow processing to extract range measurements. These methods work only when the platform velocity is sufficient to induce detectable changes in the pixel array. Also, spectrometers are passive sensors, meaning they record reflected light from variable environmental sources, especially the sun. Tracking changes in intensity or colour across the pixel array becomes difficult without the consistency of a controlled energy source, or on low-contrast surfaces, hampering the detection of objects which would be used to compute ranges.

One or more single-beam laser range finders can be mounted statically, on a scanning gimbal or in a mixture of configurations. Laser rangefinders are active scanners that emit laser pulses and measure the time of return from a subject to compute the subject distance. Environmental conditions and scene contrast are not likely to affect measurement accuracy, however point density reduced by scattering, absorbtion or reflection on some surfaces. 

A rotating beam laser scanner, such as the Velodyne VLP-C32, which provides a $40\deg$ vertical and $360\deg$ horizontal field of view, can be mounted vertically to give wide swath that extends from nadir to the horizon. The point density of such instruments can provide a highly accurate and detailed model of the terrain, but they are currently heavy and expensive. 

Finally, one or more single-beam rangea and sufficient spread that, if mounted vertically, would provide the desired coverage. Finally, one or more single-beam laser rangefinders could be arranged to sample the space between nadir and the forward-facing laser.

The analysis should consider a parameter that adjusts the transition distance (i.e., smoothing) between zero and some limit, in consideration of the impact on data quality.

Unlike missiles and jet aircraft, the attitude of an aerial remote-sensing vehicle is of utmost importance. Nadir-aligned sensors should remain as close to nadir as possible. While it is possible to rapidly change a vehicle's velocity, doing so requires radical changes to the thrust and attitude of the vehicle which disrupts the alignment of the instruments and degrades the data quality.



Studies into missiles and high-speed jet aircraft carefully consider the role of inertia, drag, thrust, lift and other dynamic effects on the airframe so that the autopilot system can anticipate changes in terrain. 

** The aircraft attitude is important to data quality. We can't just halt the platform by applying maximum thrust and pitching upward. The aircraft must either coast to a velocity which permits smooth transititions in trajectory without disrupting the attitude, or it must smooth its trajectory: a compromise.



How to follow closely behind hills, etc. 

How to anticipate and adjust for upcoming changes.

Following digital surface or terrain: DIFFFERENT!

no need for attitude adjustment -- want to avoid it




\subsection{Remote-Sensing UAVs}

This research will concentrate on the control of multi-rotor UAVs carrying hyperspectral and LiDAR instruments.

UAVs offer many advantages over traditional, manned aerial platforms. First among these is cost. Fixed-wing and rotary surveys may cost thousands of dollars per flight-hour. The instrumentation required for such surveys may cost hundreds of thousands or millions  of dollars. Flight planning and execution of a UAV survey can be accomplished rapidly, and changes to a flight plan do not represent a significant delay or expense. A UAV survey need not originate at an airport. The training required to operate a UAV in accordance with federal regulations, while substantial, is trivial in comparison to pilot training and certification, and a UAV pilot need not be dedicated to the profession. Most importantly, the low platform elevation of a UAV survey radically increases the attainable resolution for raster products and point density for LiDAR products.

There are mechanisms for enabling “terrain following” for UAVs, which depend on the pre-existence of a digital surface model (DSM.) This has two consequences: first, that the survey must have been performed previously and the resulting data processed into a DSM; second, that the DSM must be of sufficient quality, accuracy and detail to control the UAV safely, given the nature of the terrain, ground cover and the flight elevation. Currently-available solutions use the Shuttle Radar Topography Mission (STRM) elevation model, which is one of few freely-accessible global DEMs, but is not a true DSM; C-band RADAR may penetrate up to half way into a forest canopy \cite{Carabajal2005} and will penetrate into snow, depending on its porosity and wetness \cite{Tighe2009}. The maximum resolution of the SRTM DEM is30' (approximately 30m) horizontally and 1m vertically, with stated vertical accuracy of $\leq$16m, much too large for low-elevation remote sensing work, particularly in steep or forested terrain.  

An ideal solution would be for the UAV to compute a terrain model on its own, in real time, and follow the terrain at a fixed elevation while executing its flight plan. The system provides an opportunity to implement obstacle avoidance: objects that are identified as non-ground, yet obstruct UAV’s trajectory may be used to signal a return-to-home response, or a go-around plan and, depending on the uncertainty inherent in the instrument, the point cloud generated by a forward-facing laser may be contributed to that of the downward-facing main LiDAR, both to densify it and to contribute views of the subject from fore and aft, rather than only left and right, as is typical. 

\subsection{LiDAR}

Light detection and ranging (LiDAR) is a relatively new technology that uses one or more laser rangefinders to construct a three-dimensional representation of the environment. In most applications, a spinning mirror deflects a laser pulse towards a subject, and a detector measures the intensity of the reflected light as it returns. Solid-state LiDAR devices are also available as single-beam rangefinders or multi-or split-beam scanners. From a solid surface, a single pulse will return, but from a complex subject, such as a forest canopy, a pulse may reflect several times at multiple ranges. The pulse returns are interpreted by the detector as a continuous waveform which records intensity versus time, from which a fixed number -- typically one to five -- of discrete points may be extracted at the peaks of the wave. Time is, of course, directly related to range by the speed of light. From original polar coordinates (angle and range), each pulse is transformed to a Cartesian (x, y, z) representation from which a “point cloud” is compiled. These points clouds have many uses in the sciences, including the analysis of forest canopy structure and the production of precise terrain models. 

There are several measures of data quality as regards LiDAR data, including relative and abolute vertical and horizontal accuracy and point density. Point density represents the number of discrete cartesian points that can be found within a unit of continuous space, commonly described by a grid. Because a LiDAR instrumen emits a fixed number of pulses per unit time, and because the instrument-to-target distance is proportional to the coverage area, it is clear that point density declines with elevation. 

Point density has scale-determined implications for research. If a researcher is attempting to describe the canopy structure of 90m-tall old-growth forests, a high platform elevation is required to both to cover a large enough forest to acquire a significant number of crowns, but minimize the variance in point density between the ground and the tree top. Fortunately, the point density required for the study of such enormous plants is much lower than that required for, say, a grape vine. To characterize the structure of a grape vine, point density must be suitably high, which, using the same instrument as above, requires a lower flight elevation. If a vinyard is situated in a valley with considerable relief, the variance in point cloud density at a constant elevation may reduce the data quality in lower-elevation  parts of the study area.

There are at least two ways to adress this. First, by raising the platform elevation, the point density variance is reduced, however the point density is also reduced by a corresponding amount; and second, by following the terrain at a constant relative elevation.

A LiDAR instrument may be used at ground level, mounted on a tripod, or installed in an aircraft for aerial surveys. Recently, the explosion of interest in autonomous automobiles has sparked something of a gold rush in the development of compact LiDAR devices which can be mounted on vehicles to assist with modelling their environment. These devices, optimized for compactness and low cost, are ideal for another application: unmanned aerial vehicles (UAVs).

DATA QUALITY? WHAT DOES IT MEAN?


\subsection{Hyperspectral}

...


DATA QUALITY? WHAT DOES IT MEAN?


\subsection{SLAM}

Simultaneous localization and mapping.

Traditional terrain-following mechanisms used RADAR for measuring the distance from aircraft to terrain. The advent of cheap, lightweight LiDAR instruments, primarily designed for the autonomous vehicle market, has made available 


The Kalman Filter \cite{Kalman1960} is a recursive least-squares optimizing function that effectively converges on a true value -- in one or more dimensions -- at each time step by assigning a weight to the current state and the inputs depending on the confidence in each, and generating a new state estimate which will be subjected to the same process on the next time step. A primary consideration in the development of state-space smoothing methods such as Kalman's is the impossibility of storing a complete history of the object's state and estimating its immediate future based on its entire past. The latter would entail an ever-increasing processing load, as the object's history grew. Another consideration is the temporal variability in the certainty of new estimates of the object's state (i.e. measurements). As these vary through time, they would also have to be stored and computed to derive an estimate of the object's state. The Kalman filter solves these problems by considering only the object's present state, the inputs, and an error estimate for each \cite{Swerling1959}. 

Kalman filtering was originally used for estimating the trajectories of the Apollo lunar landers and for RADAR tracking of targets \cite{Grewal2010}, but is widely used in climate science, econometrics, engineering, especially in the field of robotics. Autonomous robots, UAVs included, must have reliable information their position, orientation and velocity in order to interac effectively with the environment. Airborne vehicles, in particular, must have accurate information about their position and orientation, but also their trajectory.

A typical UAV uses the Global Positioning System (GPS) for absolute positioning and an inertial navigation system (INS) for measuring acceleration and orientation. These inputs together allow the vehicle to ajust its attitude and velocity to maintain a pre-defined trajectory, and -- arguably, more importantly -- for georeferencing collected data. There are numerous sources of measurement error inherent in GPS and INS measurements which hamper the vehicle's ability to ascertain its instantaneous state; the Kalman filter provides a means of determining its true state with a high degree of confidence.

[Extended Kalman filter -- local linearization?]

\subsection{Trajectory}

...

Discuss current solutions: Maps Made Easy.



\subsection{Ground Classification}

Single-beam vs. multi-beam.

Multi-element vs. planar. \cite{Nobili2015}

The technology for automating ground classification is not mature \cite{Vosselman2001,Vosselman2000} and perfection is, of course, not possible. But what are the implications for UAV control? The point density of the instrument is likely to be limited, as is the capability of processing the full cloud. A higher density is better for classification, but instrument noise and vegetation present serious issues. What if the point cloud cannot penetrate into the canopy? The drone may have some way of reconciling a naive assumption about the nature of the terrain, and the information is receiving from the scanner?


\subsection{Alternatives to LiDAR}

** What if we just use the down-facing lidar and use predictive method to anticipate changes in terrain? Drawback, no obstacle avoidance.

** Photogrammetry -- no penetration.

** Optical flow -- traditional robotics technique, used by insects. Same limitations as photogrammetry.


\section{Development}


\subsection{Simulation}

Given the variety of laser scanner types and configurations, and the variety of terrain and ground-cover types a UAV may encounter, it is prudent to attempt to simulate and assess a variety of virtual instruments and conditions before purchasing hardware. Several rangefinder configurations are listed in figure \ref{list:rangefinder_configs}.

\begin{itemize}
\item Single-beam, single-return.
\item Single-beam, multi-return.
\item Single-beam, single-return with a servo driver for mechanical, side-to-side scanning.
\item Split-beam, multi-return, solid-state.
\item Multi-beam, multi-return, solid-state.
\item single-beam, multi-return, spinning laser.
\item Multi-beam, multi-return, spinning laser.
\item Multi-beam, multi-return, spinning mirror.
%% \caption{Laser rangefinder configurations.}
\label{list:rangefinder_configs}
\end{itemize}

It must also be determined which sampling method is optimal. A static single-beam range finder will produce a series of points in a line along trajectory of the platform. This may be sufficient to detect the surface elevation directly in front of the platform, but may not be robust to noise, may not enable the detection of ground returns, and will not produce a useful side-view when the vehicle is turning. Single-beam lasers are cheap and lightweight, which reduces the load on the platform's power supply. A fan-shaped scanning pattern would produce a 3-dimensional point cloud which would enable ground point filtering, some noise removal and limited side-looking ability in turns. These instruments are more costly and heavier, but may be able to contribute to improved data quality and platform safety. Single-beam rangefinders may be mounted statically or on a servo, which scans back and forth across the terrain in a sinusoidal fasion (figure \ref{fig:sinus_plane}).

The output of any rangefinder can be simulated by defining a terrain-generating function and sampling it at positions that would be read by the instrument. Gaussian noise can be applied to the samples simulate measurement error using the characteristics documented by the manufacturer or testing. In a real-world scenario, it would be neccessary to account for uncertainty about the vehicle's elevation and the actual elevation of the terrain. In a simulated environment these can be controlled, leaving only the optimality of the trajectory to be assessed.

Figure \ref{fig:point_plane} shows an example of the output of a hypothetical regular sampling of a planar surface. The first plot shows the outcome using measurements with zero uncertainty. In the second and third images, the measurements are perturbed by random Gaussian noise with standard deviations of 0.001 and 0.01, respectively, to simulate error.

\begin{figure}
\centering
\def\svgscale{0.4}
\input{build/images/plane_grid_0.pdf_tex}
\def\svgscale{0.4}
\input{build/images/plane_grid_0001.pdf_tex}
\def\svgscale{0.4}
\input{build/images/plane_grid_001.pdf_tex}
\caption{Simulated grid sampling of planar surface with Gaussian error; $\sigma 0$, $\sigma 0.01$ and $\sigma 0.001$.}
\label{fig:point_plane}
\end{figure}


Figure \ref{fig:sinus_plane} shows the result when the planar model is scanned in a sinusoidal fasion by a servo-mounted rangefinder.

\begin{figure}
\centering
\def\svgscale{0.4}
\input{build/images/plane_sinus_0.pdf_tex}
\def\svgscale{0.4}
\input{build/images/plane_sinus_0001.pdf_tex}
\def\svgscale{0.4}
\input{build/images/plane_sinus_001.pdf_tex}
\caption{Simulated sinusoidal scan of planar surface with Gaussian error; $\sigma 0$, $\sigma 0.01$ and $\sigma 0.001$.}
\label{fig:sinus_plane}
\end{figure}


Figure \ref{fig:linear_plane} shows the result when the planar model is scanned in a linear fasion by a statically-mounted rangefinder.

\begin{figure}
\centering
\def\svgscale{0.4}
\input{build/images/plane_linear_0.pdf_tex}
\def\svgscale{0.4}
\input{build/images/plane_linear_0001.pdf_tex}
\def\svgscale{0.4}
\input{build/images/plane_linear_001.pdf_tex}
\caption{Simulated linear scan of planar surface with Gaussian error; $\sigma 0$, $\sigma 0.01$ and $\sigma 0.001$.}
\label{fig:linear_plane}
\end{figure}

Figure \ref{fig:plane_object} shows the result of scanning a plane with a square object using a grid, sinusoidal scan and linear scan.

\begin{figure}
\centering
\def\svgscale{0.4}
\input{build/images/block_grid_0.pdf_tex}
\def\svgscale{0.4}
\input{build/images/block_sinus_0.pdf_tex}
\def\svgscale{0.4}
\input{build/images/block_linear_0.pdf_tex}
\caption{Simulated scans of planar surface with obstacle.}
\label{fig:plane_object}
\end{figure}


Any rangefinder configuration

of these can be simulated by reading an existing real-world or generated point cloud, applying parametric noise and densification, and streaming the points into the navigation system as if they were being produced at flight time by a rangefinder. If a real-world point cloud is used, the measurement error inherent in the original product may be maintained or increased, and it may be densified using the documented nominal uncertainty for the campaign. A modeled terrain, such as a simple plane or three-dimensional polynomial surface, with or without objstructions, can be sampled at an arbitrary density and the samples perturbed using Brownian or Gaussian noise.

Simulate a variety of terrain conditions: Flat, sloped, undulating, etc. with and without obstacles

Generate simulated point clouds as if from a rangefinder or scanner, single or multibeam.

Add parameterized noise to the simulated measurements to simulate real-world noisy measurements.

Generate noisy vehicle position inputs, etc.

LIDAR ACCURACY \cite{May2007}




\subsection{Control}

Control Loops








** Most (all?) current applications use a nadir laser and reactive paradigm. I want to create a smoothed trajectory with configurable limits (for safety) based on a predictive regime. a) from facing forward, and b) from computing trends based on past measurements.

** Kalman filter. Can be used to compute a trajectory from the vehicle’s current state and inputs from instruments, and flight plan. 



Photogrammetry
Still a possibility

Makers:
Velodyne (solid state lidar coming)
Quanergy (S3)
AEye
Leddar (range sucks; 20m @ 18% grey)

Purpose: Build a system that:

\begin{itemize}
\item Ascertains the vehicle's state using GPS and INS inputs and the Kalman filter.
\item Ascertains the elevation some fixed distance in front of the vehicle using a forward-facing rangefinder; multi- or single-beam TBD; ground classification requirements TBD.
\item Adjusts the 2D trajectory using the vehicle's state and future changes in elevation using some smoothing method (possibly Kalman) as well as insight gleaned from other terrain following methods.
\item Controls the vehicle so that it will follow the trajectory.
\end{itemize}


\bibliographystyle{plain}
\bibliography{/home/rob/Documents/bibtex/library.bib}


\end{document}