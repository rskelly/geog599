%%  Doesn't work... \usepackage{apacite}	% for APA format; requires sudo apt-get install texlive-bibtex-extra

\documentclass[10pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{setspace}	% for line spacing
\usepackage{calc}		% for figure scaling
\usepackage{svg}		% for graphics
\usepackage{graphicx}	% for graphics
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\author{Rob Skelly}
\title{Real-Time Terrain Following and Trajectory Adjustment for Remote-Sensing Unmanned Aerial Vehicles}

% Images are build by calling images/generate.sh <images> <output> where
% output is the "build" directory used by Texmaker.
\graphicspath{{./build/images/}}

\begin{document}

\maketitle

\doublespace

\section{Introduction}

Purpose: Build a system that:

\begin{itemize}
\item Ascertains the vehicle's state using GPS and INS inputs and the Kalman filter.
\item Ascertains the elevation some fixed distance in front of the vehicle using a forward-facing rangefinder; multi- or single-beam TBD; ground classification requirements TBD.
\item Adjusts the 2D trajectory using the vehicle's state and future changes in elevation using some smoothing method (possibly Kalman) as well as insight gleaned from other terrain following methods.
\item Controls the vehicle so that it will follow the trajectory.
\end{itemize}

\subsection{Remote Sensing Platforms}

Remote sensing is the art and science of sensing, or measuring, objects without the necessity direct physical contact using instruments designed for this purpose. Generally, remote sensing refers to sensing of the environment, of objects on the Earth, from air- or spacecraft, though it can just as easily involve handheld or tripod-mounted instruments. Such instruments might include a spectrometer for measuring the electromagnetic reflectivity of an object or a laser scanner for describing its structure in three dimensions. Indeed, three of a human being’s five senses (smell, sight, hearing) are, in a sense, remote-sensing instruments; remote sensing is as natural to human beings as walking. Fortunately, the evolution of remote sensing technology has provided a means of collecting quantitative insights into phenomena formerly inaccessible to the human sensory apparatus, at distances and scales previously unattainable.

Remote sensing has a virtual infinity of use-cases, from inventorying buildings in a city, to assessing road quality, plant heath, and timber volumes, measuring the extent of arctic sea ice and forest fires, to tracking weather systems and determining the integrity of hydroelectic dams. Of particular interest are the different spatial scales at which each of the above subjects must be studied. Sea ice and weather systems, for example, may be investigated at a hemispheric scale, while plant health studies may investigate the fine structure of individual plants no more than a metre tall. By its nature, remote sensing demands the consideration of space, in terms of both the contextualization and interpretation of information so acquired, and of managing their effects on data quality. These considerations carry through from the choice of acquisition distances, instruments and platforms, to the representation and interpretation of remotely-sensed data.

Air- and spaceborne remote sensing platforms can be separated in to three distinct categories: spacecraft, fixed-wing and rotary aircraft, and small, unmanned fixed-wing or rotary aerial vehicles.  In addition, there are large, unmanned aerial vehicles used primarily for militatary purposes. Each platform entails benefits and drawbacks which can be considered on a spectrum.

\begin{table}
\caption{Comparison of remote sensing platform characteristics.}
\label{table:platforms}
\begin{tabular}{l|ccc}
\hline
 & Satellite & Aircraft & UAV \\
\hline
Scale & Global & Local & Hyper-local \\
Subject Distance & High & Medium & Low \\
Resolution & Low & Medium & High \\
Consistency & High & Medium & Low \\
Atmospheric Effects & High & Medium & Low \\
Platform Cost & High & Medium & Low \\
Per-Mission Cost & High & Medium & Low \\
Topographic Effects & Low & Medium & High \\
\hline
\end{tabular}
\end{table}

\subsection{Topographic Effects}

The final element in table \ref{table:platforms} is of particular interest. The native resolution of an imaging device, such as an imaging spectrometer, is determined by its instantaneous field of view (IFOV) -- the solid angle within which the instrument is sensitive to radiation -- and the instument-to-subject distance, or elevation, as related by
\begin{equation}
r = \sqrt{\sin{\theta}^2+\cos{\theta}^2}*e,
\label{eq:ifov}
\end{equation} 
where $r$ and $e$ are the resolution and elevation in the same units and $\theta$ is the IFOV. A similar relation exists between platform elevation and the point density of a LiDAR instrument. In either case, the size of object resolvable by the instrument is directly controlled by the platform's elevation. A side effect of the above relation is that it induces distortion in the image of the subject. As an example, figure \ref{fig:scale_cam} shows a downward-facing camera with one subject twice as far from the instrument as the other. In the image view (figure \ref{fig:scale_img}), the nearer object is twice as large (and therefore twice as detailed) as the far one and appears to be offset from the camera's optical axis.

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/scale_topography_cam.pdf_tex}
\caption{Side view of down-facing camera with subjects.}
\label{fig:scale_cam}
\end{figure}

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/scale_topography_img.pdf_tex}
\caption{Resulting image with scale distortion.}
\label{fig:scale_img}
\end{figure}


Topographic effects have to do with the effect that variations in terrain elevation have on the instrument-to-subject distance from a platform at constant elevation and hence on the precision of measurement. The highest point on Earth (Mount Everest, Nepal; 8848m) and the lowest (Dead Sea, Jordan; 431m), represent a difference of 9279m, a variation of 4.0\% relative to the orbit (233km) of the  Shuttle Radar Topography Mission, corresponding to a 4.0\% variation its native spatial resolution. For a fixed-wing aircraft flying at a typical survey altitude of 5000m a scale distortion of a similar scale would require a change in elevation of 200m. For a UAV flying at the typical survey altitude of 35m, the variation in terrain elevation sufficient to induce an equivalent distortion would be 1.4m.

The converse is true: SRTM would not be considered appropriate for the measurement of local, small-scale terrain variations for the same reason that it was suitable for imaging Mount Everest, while a UAV would be considered ideal for imaging terrain at a small scale. However, a conundrum regarding scale remains. A UAV can image small scale relief but must also negotiate or avoid larger terrain features both to maintain data quality and to avoid a collision.


\subsection{Terrain Following}

Research into terrain following has been continuing since the 1960s for the control of ballistic missiles and jet aircraft \cite{KRACHMALNICK1968,Starling1971,Cunningham1980}. Such systems use a forward- and downward-facing RADAR rangefinder to detect the terrain elevation some distance ahead of the vehicle, some means of terrain classification \cite{Cunningham1980}, and a method of altering the vehicle's trajectory to follow the terrain surface as closely as possible. Research on terrain following for military aircrafts and missiles has been focused on high-speed, low elevation flight with a premium placed on stealth. Neither high speed nor stealth are desireable for a remote sensing mission but many of the same concerns persist. 

How to follow closely behind hills, etc. 

How to anticipate and adjust for upcoming changes.

Following digital surface or terrain: DIFFFERENT!

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/uav_terrain.pdf_tex}
\caption{Terrain-following UAV.}
\label{fig:uav_terrain}
\end{figure}

Terrain following for UAVs is a necessary and achievable goal, for the maximization of data quality, the safety of the instrument and people and animals in the study area, and for the ease and efficiency of flight planning.

\section{Research Questions}

\begin{itemize}
\item What is the ideal rangefinder instrument for forward-looking elevation measurement for the purpose of automated terrain following?
\item What method of ground-point filtering, if any, is optimal for terrain following?
\item How can a two-dimensional UAV flight plan best be modified to account for topographic variation, given the constraints on platform control and the need to maintain data quality.
\item What are the operational constrains, if any? (Data volume, I/O bottlenecks, storage capacity, etc.)
\end{itemize}

\section{Background}

\subsection{Remote-Sensing UAVs}

This research will concentrate on the control of multi-rotor UAVs carrying hyperspectral and LiDAR instruments.

UAVs offer many advantages over traditional, manned aerial platforms. First among these is cost. Fixed-wing and rotary surveys may cost thousands of dollars per flight-hour. The instrumentation required for such surveys may cost hundreds of thousands or millions  of dollars. Flight planning and execution of a UAV survey can be accomplished rapidly, and changes to a flight plan do not represent a significant delay or expense. A UAV survey need not originate at an airport. The training required to operate a UAV in accordance with federal regulations, while substantial, is trivial in comparison to pilot training and certification, and a UAV pilot need not be dedicated to the profession. Most importantly, the low platform elevation of a UAV survey radically increases the attainable resolution for raster products and point density for LiDAR products.

There are mechanisms for enabling “terrain following” for UAVs, which depend on the pre-existence of a digital surface model (DSM.) This has two consequences: first, that the survey must have been performed previously and the resulting data processed into a DSM; second, that the DSM must be of sufficient quality, accuracy and detail to control the UAV safely, given the nature of the terrain, ground cover and the flight elevation. Currently-available solutions use the Shuttle Radar Topography Mission (STRM) elevation model, which is one of few freely-accessible global DEMs, but is not a true DSM; C-band RADAR may penetrate up to half way into a forest canopy \cite{Carabajal2005} and will penetrate into snow, depending on its porosity and wetness \cite{Tighe2009}. The maximum resolution of the SRTM DEM is30' (approximately 30m) horizontally and 1m vertically, with stated vertical accuracy of $\leq$16m, much too large for low-elevation remote sensing work, particularly in steep or forested terrain.  

An ideal solution would be for the UAV to compute a terrain model on its own, in real time, and follow the terrain at a fixed elevation while executing its flight plan. The system provides an opportunity to implement obstacle avoidance: objects that are identified as non-ground, yet obstruct UAV’s trajectory may be used to signal a return-to-home response, or a go-around plan and, depending on the uncertainty inherent in the instrument, the point cloud generated by a forward-facing laser may be contributed to that of the downward-facing main LiDAR, both to densify it and to contribute views of the subject from fore and aft, rather than only left and right, as is typical. 

\subsection{LiDAR}

Light detection and ranging (LiDAR) is a relatively new technology that uses one or more laser rangefinders to construct a three-dimensional representation of the environment. In most applications, a spinning mirror deflects a laser pulse towards a subject, and a detector measures the intensity of the reflected light as it returns. Solid-state LiDAR devices are also available as single-beam rangefinders or multi-or split-beam scanners. From a solid surface, a single pulse will return, but from a complex subject, such as a forest canopy, a pulse may reflect several times at multiple ranges. The pulse returns are interpreted by the detector as a continuous waveform which records intensity versus time, from which a fixed number -- typically one to five -- of discrete points may be extracted at the peaks of the wave. Time is, of course, directly related to range by the speed of light. From original polar coordinates (angle and range), each pulse is transformed to a Cartesian (x, y, z) representation from which a “point cloud” is compiled. These points clouds have many uses in the sciences, including the analysis of forest canopy structure and the production of precise terrain models. 

There are several measures of data quality as regards LiDAR data, including relative and abolute vertical and horizontal accuracy and point density. Point density represents the number of discrete cartesian points that can be found within a unit of continuous space, commonly described by a grid. Because a LiDAR instrumen emits a fixed number of pulses per unit time, and because the instrument-to-target distance is proportional to the coverage area, it is clear that point density declines with elevation. 

Point density has scale-determined implications for research. If a researcher is attempting to describe the canopy structure of 90m-tall old-growth forests, a high platform elevation is required to both to cover a large enough forest to acquire a significant number of crowns, but minimize the variance in point density between the ground and the tree top. Fortunately, the point density required for the study of such enormous plants is much lower than that required for, say, a grape vine. To characterize the structure of a grape vine, point density must be suitably high, which, using the same instrument as above, requires a lower flight elevation. If a vinyard is situated in a valley with considerable relief, the variance in point cloud density at a constant elevation may reduce the data quality in lower-elevation  parts of the study area.

There are at least two ways to adress this. First, by raising the platform elevation, the point density variance is reduced, however the point density is also reduced by a corresponding amount; and second, by following the terrain at a constant relative elevation.

A LiDAR instrument may be used at ground level, mounted on a tripod, or installed in an aircraft for aerial surveys. Recently, the explosion of interest in autonomous automobiles has sparked something of a gold rush in the development of compact LiDAR devices which can be mounted on vehicles to assist with modelling their environment. These devices, optimized for compactness and low cost, are ideal for another application: unmanned aerial vehicles (UAVs).


\subsection{SLAM}

Simultaneous localization and mapping.

Traditional terrain-following mechanisms used RADAR for measuring the distance from aircraft to terrain. The advent of cheap, lightweight LiDAR instruments, primarily designed for the autonomous vehicle market, has made available 

\subsection{Ground Classification}

Single-beam vs. multi-beam.

Multi-element vs. planar. \cite{Nobili2015}

The technology for automating ground classification is not mature \cite{Vosselman2001,Vosselman2000} and perfection is, of course, not possible. But what are the implications for UAV control? The point density of the instrument is likely to be limited, as is the capability of processing the full cloud. A higher density is better for classification, but instrument noise and vegetation present serious issues. What if the point cloud cannot penetrate into the canopy? The drone may have some way of reconciling a naive assumption about the nature of the terrain, and the information is receiving from the scanner?

\subsection{Position-Finding}

The Kalman Filter \cite{Kalman1960} is a recursive least-squares optimizing function that effectively converges on a true value -- in one or more dimensions -- at each time step by assigning a weight to the current state and the inputs depending on the confidence in each, and generating a new state estimate which will be subjected to the same process on the next time step. A primary consideration in the development of state-space smoothing methods such as Kalman's is the impossibility of storing a complete history of the object's state and estimating its immediate future based on its entire past. The latter would entail an ever-increasing processing load, as the object's history grew. Another consideration is the temporal variability in the certainty of new estimates of the object's state (i.e. measurements). As these vary through time, they would also have to be stored and computed to derive an estimate of the object's state. The Kalman filter solves these problems by considering only the object's present state, the inputs, and an error estimate for each \cite{Swerling1959}. 

Kalman filtering was originally used for estimating the trajectories of the Apollo lunar landers and for RADAR tracking of targets \cite{Grewal2010}, but is widely used in climate science, econometrics, engineering, especially in the field of robotics. Autonomous robots, UAVs included, must have reliable information their position, orientation and velocity in order to interac effectively with the environment. Airborne vehicles, in particular, must have accurate information about their position and orientation, but also their trajectory.

A typical UAV uses the Global Positioning System (GPS) for absolute positioning and an inertial navigation system (INS) for measuring acceleration and orientation. These inputs together allow the vehicle to ajust its attitude and velocity to maintain a pre-defined trajectory, and -- arguably, more importantly -- for georeferencing collected data. There are numerous sources of measurement error inherent in GPS and INS measurements which hamper the vehicle's ability to ascertain its instantaneous state; the Kalman filter provides a means of determining its true state with a high degree of confidence.

[Extended Kalman filter -- local linearization?]

\subsection{Trajectory}


\subsection{Alternatives to LiDAR}

** What if we just use the down-facing lidar and use predictive method to anticipate changes in terrain? Drawback, no obstacle avoidance.

** Photogrammetry -- no penetration.

** Optical flow -- traditional robotics technique, used by insects. Same limitations as photogrammetry.

\section{Development}

\subsection{Simulation}

Given the variety of laser scanner types and configurations, and the variety of terrain and ground-cover types a UAV may encounter, it is prudent to attempt to simulate and assess a variety of virtual instruments and conditions before purchasing hardware. Several rangefinder configurations are listed in figure \ref{list:rangefinder_configs}.

\begin{itemize}
\item Single-beam, single-return.
\item Single-beam, multi-return.
\item Single-beam, single-return with a servo driver for mechanical scanning.
\item Split-beam, multi-return, solid-state.
\item Multi-beam, multi-return, solid-state.
\item Multi-beam, multi-return, spinning laser.
\item Multi-beam, multi-return, spinning mirror.
%% \caption{Laser rangefinder configurations.}
\label{list:rangefinder_configs}
\end{itemize}

It must be determined which sampling method is optimal. A single-beam range finder will produce a series of points along a line in front of the platform. This may be sufficient to detect the surface elevation directly in front of the platform, but may not be robust to noise, may not enable the detection of ground returns, and will not produce a useful side-view when the vehicle is turning. Single-beam lasers are cheap and lightweight, which reduces the load on the platform's power supply. A fan-shaped scanning pattern would produce a 3-dimensional point cloud which would enable ground point filtering, some noise removal and limited side-looking ability in turns. These instruments are more costly and heavier, but may be able to contribute to improved data quality and platform safety. Single-beam rangefinders may be mounted statically or on a servo, which scans back and forth across the terrain.

The output of any rangefinder can be simulated by defining a terrain-generating function and sampling it at positions that would be read by the instrument. A noise function can be applied, which is configured using the instrument's documented error characteristics. 



Any rangefinder configurationof these can be simulated by reading an existing real-world or generated point cloud, applying parametric noise and densification, and streaming the points into the navigation system as if they were being produced at flight time by a rangefinder. If a real-world point cloud is used, the measurement error inherent in the original product may be maintained or increased, and it may be densified using the documented nominal uncertainty for the campaign. A modeled terrain, such as a simple plane or three-dimensional polynomial surface, with or without objstructions, can be sampled at an arbitrary density and the samples perturbed using Brownian or Gaussian noise.

Simulate a variety of terrain conditions: Flat, sloped, undulating, etc. with and without obstacles

Generate simulated point clouds as if from a rangefinder or scanner, single or multibeam.

Add parameterized noise to the simulated measurements to simulate real-world noisy measurements.

Generate noisy vehicle position inputs, etc.

LIDAR ACCURACY \cite{May2007}

\begin{figure}
\centering
\def\svgscale{0.4}
\input{build/images/smooth_plane.pdf_tex}
\def\svgscale{0.4}
\input{build/images/sigma_0001_plane.pdf_tex}
\def\svgscale{0.4}
\input{build/images/sigma_001_plane.pdf_tex}
\caption{Planar point clouds surfaces with Gaussian error; $\sigma 0$, $\sigma 0.01$ and $\sigma 0.001$.}
\label{fig:plane_smooth}
\end{figure}


\section{Background}

Of particular interest is the effect of distance on the precision of measurement, which may be encountered in several different ways. Consider the issue of point density:







** Most (all?) current applications use a nadir laser and reactive paradigm. I want to create a smoothed trajectory with configurable limits (for safety) based on a predictive regime. a) from facing forward, and b) from computing trends based on past measurements.
** Kalman filter. Can be used to compute a trajectory from the vehicle’s current state and inputs from instruments, and flight plan. 



Photogrammetry
Still a possibility

Makers:
Velodyne (solid state lidar coming)
Quanergy (S3)
AEye
Leddar (range sucks; 20m @ 18% grey)

\bibliographystyle{plain}
\bibliography{/home/rob/Documents/bibtex/library.bib}

\end{document}