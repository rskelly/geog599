%%  Doesn't work... \usepackage{apacite}	% for APA format; requires sudo apt-get install texlive-bibtex-extra

\documentclass[10pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{siunitx}
\usepackage{setspace}	% for line spacing
\usepackage{calc}		% for figure scaling
\usepackage{svg}		% for graphics
\usepackage{graphicx}	% for graphics
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}
\usepackage{listings}

\fontfamily{ptm}

% Images are build by calling images/generate.sh <images> <output> where
% output is the "build" directory used by Texmaker.
\graphicspath{{./build/images/}}

\DeclareUnicodeCharacter{2010}{ }

\author{Rob Skelly}
\title{Real-Time Terrain Following and Trajectory Adjustment for Remote-Sensing Unmanned Aerial Vehicles}

\lstset{%
  basicstyle=\small\ttfamily,
  language=Python
}

\begin{document}

\maketitle

\doublespace

\section{Introduction}

Remote sensing is the art and science of sensing, or measuring, objects without the necessity of direct physical contact between the subject and the observer. Three of the human sense organs --- the eyes, ears and nose --- are remote sensing instruments, though remote sensing more commonly refers to the quantitative observation of objects on the Earth, in a geospatial context, using technology designed for this purpose. Remote sensing instruments are typically mounted on air- or spacecraft, though they can just as easily be handheld or tripod-mounted. Such instruments might include a spectrometer for measuring the electromagnetic reflectance of an object or a laser rangefinder scanner (LiDAR) for describing its structure in three dimensions. Satellite and airborne remote sensing have many use-cases, from tracking sea ice extent \cite{Dierking2006,Shuchman2004}, to estimating standing timber volumes \cite{Allouis2011,Tonolli2011}, to investigating plant health at the scale of a single leaf \cite{Palou2013}.

The scale of the phenomenon under investigation, in part, determines the distance from the instrument to the subject. Sea ice, for example, must be observed at a hemispheric scale from a high-orbit satellite, while a study of the fine structure of individual plants must be performed at a much smaller remove. A large resolution of 25m-1000m \cite{Shuchman2004} might be suitable for the study of Arctic ice extent while 5cm or less \cite{Palou2013} would be appropriate for the study of plant health at the leaf level. 

The subject distance has a deterministic relationship with the resolution of a given instrument, where resoluton is defined as the minimum size of object that can be discriminated. If an object is larger than the resolution of an individual element in a spectrometer, that element's specta will be pure --- they will not be contaminated by those of surrounding objects. If, on the other hand, the object is smaller than the instrument's resolution, the spectra will be mixed. This hampers the researcher's ability to accurately identify objects in the image \cite{Lillesand1999}. In the case of point data, such as that produced by LiDAR, increasing the subject distance reduces the point density which, in turn, reduces the number of points associated with an object of interest. In this case, the power of any statistical analysis of points related to that object is reduced. 

The resolution of an instrument is determined by its instantaneous field of view (IFOV), that is the solid angle around the instrument's measurement axis, within which it is sensitive to incoming information \cite{Lillesand1999}. Resolution, subject distance and IFOV are related by the identity, 

\begin{equation}
r = d \theta
\label{eq:ifov}
\end{equation} 
where $r$ and $d$ are the resolution and distance linear units and $\theta$ is the IFOV in radians \cite{Lillesand1999}. A similar relation exists between platform elevation and the point density of a LiDAR instrument, where the scan angle is analogous to the IFOV. 

A side effect of the relation in eq. \ref{eq:ifov} is that changes in the subject distance induce along track (for a moving instrument) scale distortion in the image. As an example, figure \ref{fig:scale_cam} shows a nadir-aligned camera with the black object twice as far from the instrument as the white object. In the image view (figure \ref{fig:scale_img}), the nearer object appears twice as large --- and therefore twice as detailed --- as the far one. 

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/scale_topography_cam.pdf_tex}
\caption{Side view of nadir-aligned camera with subjects.}
\label{fig:scale_cam}
\end{figure}

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/scale_topography_img.pdf_tex}
\caption{Resulting image with scale distortion.}
\label{fig:scale_img}
\end{figure}

It is clear that subject distance and, therefore, platform elevation, in the case of airborne instruments, have important effects on the quality of remotely-sensed data. It follows that, in the interest in maintaining the resolution and point density of remotely-sensed data, it is necessary to control the elevation of an airborne platform to account for variation in the surface elevation, particularly at lower elevations and smaller scales, where such variations have a relatively larger effect. In the case of unmanned aerial vehicles (UAVs), where the pilot is not with the vehicle and cannot monitor and control its elevation with sufficient accuracy, this must be automated. This ability is called terrain-following (figure \ref{fig:uav_terrain}).

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/uav_terrain.pdf_tex}
\caption{Terrain-following UAV.}
\label{fig:uav_terrain}
\end{figure}

The current explosion in interest in UAVs for everything from home delivery to remote sensing to toys to military applications, has made compact UAVs more accessible to researchers than previously. Commercial-grade UAVs with payload capacities of over 6kg are now common, and at reasonable prices. However the use of UAVs for scienctific purposes, though growing, is still fairly new and use-appropriate control systems are a field of rapid development. For remote sensing applications, the need for accurate terrain following systems is being felt. Terrain following contributes not only to the safety of the vehicle and people, animals and property within the study area, but has a profound influence on the quality of data as explained previously.

UAVs offer many advantages over traditional, manned aerial platforms. First among these is cost. Fixed-wing and rotary surveys may cost thousands of dollars per flight-hour. The instrumentation required for such surveys may cost hundreds of thousands or millions  of dollars. Flight planning and execution of a UAV survey can be accomplished rapidly, and changes to a flight plan do not represent a significant delay or expense. A UAV survey need not originate at an airport. The training required to operate a UAV in accordance with federal regulations, while substantial, is trivial in comparison to pilot training and certification, and a UAV pilot need not be dedicated to the profession. Most importantly, the low platform elevation of a UAV survey radically increases the attainable resolution for raster products and point density for LiDAR products.

Coincidentally, there is a simultaneous explosion of interest robotics, and especially autonomous automobiles, which has encouraged numerous companies to rush to market with compact LiDAR devices of various types \cite{Quanergy2017,Dormehl2017,Morin2017}. These devices are designed to be light, durable and affordable and are meant to give robots and cars the ability to sense their surroundings in three dimensions, in order to navigate safely through their environment. They happen to be ideal (at least in form and cost) for use on UAVs, both for remote sensing applications, and for autonomous vehicle control.

Unfortunately, the state of the art in battery technology is not adequate to the power requirements of heavily-laden remote-sensing UAVs. The overuse of battery resources entails significant costs in terms of mission turn-around time and expense, in terms of the number of flights required to cover a study area and the number of sets of batteries required to complete a mission. The extra mass and power draw of extra rangefinders for terrain following exacerbates this problem.

These issues motivate the present research and the questions: \\

\textbf{For a remote sensing unmanned aerial vehicle,
\begin{enumerate}
\item what type and arrangement of laser rangefinder instrument(s) is best suited to the task of real-time terrain following, and;
\item what is the optimal vertical trajectory function, in terms of the stability of resolution and point density, the safety of the platform, and the conservation of on-board power?
\end{enumerate}}

Obtaining and testing all of the available --- and not-yet available --- laser rangefinders would be costly and time-consuming. This project will attempt to design computerized simulations of a variety of instruments and configurations by sampling from a variety of modelled surfaces. Such surfaces can be represented by mathematical models, such as planes and unions of geometric shapes, or collected from the real world by LiDAR devices. The sampling pattern and density will be modified to resemble the output of various laser rangefinders, and noise will be added to simulate the instruments' error charactristics. An important benefit of simlation is the ability to eliminate environmental factors and isolate the true benefits of one system over the other.

This research will be concerned with optimizing data quality for two types of instruments, a hyperspectral push-broom scanner, and a scanning LiDAR, and will attempt to quantify the distortions induced in each by the chosen terrain-following strategy. Ultimately, a multi-rotor UAV will be outfitted according to the results of the simulation for testing.


\section{Background}

\subsection{LiDAR}

Light detection and ranging (LiDAR) is a relatively new technology which uses laser pulses to measure the distance from the instrument to a surface. The typical LiDAR-equipped vehicle will use the global positioning system (GPS) for geodetic positioning, an inertial navigation system (INS) for measuring the inertial moments (attitude, angular velocity), a highly accurate clock, a computer and the laser instrument itself \cite{May2007,Lillesand1999}. LiDAR is considered an "active" sensor, as it provides its own source of energy. LiDAR works by sending out a pulse of laser light towards an object and recording the reflection of the pulse. The clock determines the time-of-return of the pulse, which then is used to calculate the distance that the pulse has travelled. The INS and GPS are then used to convert the polar coordinate of the relfector to a the three-dimensional coordinate in Cartesian space, given the known orientation of the vehicle and the fixed position of the laser. 

The laser itself may take many forms. Some LiDAR devices consist of a single, fixed laser while most consist of a single laser with a spinning or oscillating mirror that creates a linear scan pattern of repeated pusles. In the latter case, the computer has information about the orientation of the mirror and can accurately compute the position of the reflector based on this angle and the range. Recently, LiDAR devices have appeared for the autonomous vehicle market which feature multiple beams fixed to a spinning rotor. These differ from the spinning mirror type in that, with every revolution, they create multiple scan lines. Used in airborne applications, this enables re-sampling of the subject as the vehicle moves, and may result in a very high-density point cloud. The autonomous vehicle market places a premium on cost, simplicity and reliability, which has led to the proliferation of solid-state LiDAR devices. Unlike devices with rotating components, solid-state LiDARs have no moving parts and are much less likely to suffer a mechanical failure. These have the side-benefit that they are cheaper to manufacture and potentially much smaller and lighter than mechanical devices. Solid state LiDARs are available in single- and multi-beam configurations using multiple emitters, or a single emitter with a splitter.

The pulses emitted by the laser are not instantaneous, but consist of waves of light of stable intensity. The LiDAR's receiver reads the returning pulse as a waveform of time versus intensity. It discretizes this waveform and extracts the peaks as individual returns. This enables the device to extract more than one return from a single pulse. The "footprint" of a laser is not infinitely small, but tends to spread with distance. In complex environments, with multiple reflectors along the path of the laser, such as the leaves of a tree, the LiDAR may register returns from the top of the canopy, the ground and from intermediate obstructions. Some LiDAR devices record as many as five returns per pulse \cite{Lillesand1999}.

There are several measures of data quality for LiDAR data, including relative and abolute vertical and horizontal accuracy and point density. Positional accuracy may be degraded by numerous factors including platform position and attitude errors, boresight misalignment, range measurement error, scan angle error and beam divergence error \cite{May2007}, however this is somewhat beyond the scope of this project. Point density represents the number of points that can be found within a unit of continuous space, commonly described by a two-dimensional grid. Because a LiDAR instrument emits a fixed number of pulses per unit time, and because the instrument-to-target distance is proportional to the coverage area, it is clear that point density at nadir declines with elevation. 

As a LiDAR-equipped aircraft follows a flight line, a scanning LiDAR scans across the track. The pulses emitted by the instrument strike a flat surface at $90\degree$ at nadir, and at increasing oblique angles towards the ends of the scan line. The obliqueness of these angles has several consequences. First, a pulse striking a target at such an angle is likely to reflect away from the instrument, rather than back towards it; second, the increased distance that the pulse must travel increases the magnitude of the error inherent in the measurement (which is then inconsistent with the error at nadir); third, the pulse is striking the subject from the side, rather than the top, as intended. These issues are exacerbated when the platform's roll angle is non-zero. It is therefore common to filter out points within a certain distance of the flight line edge. The removal of edge points is compensated for, to some degree, by flying parallel lines with substantial overlap, up to 50\%. With this amount of overlap, every subject is effectively scanned twice. The consistency of this overlap is dependent on the consistency of the platform elevation and roll angle.

A further density-related issue is the role that platform pitch plays in the variability of point density. If the platform accelerates in the forward direction, it will pitch forward slightly, angling the scanner towards the aft, creating a region of increased point density. However, if the vehicle slows, it will pitch rearward, creating a region of reduced density. Clearly it is desireable to minimize variations in platform pitch.

Point density has scale-determined implications for research. If a researcher is attempting to describe the canopy structure of 90m-tall old-growth forests, the platform elevation must be sufficient for the mission to encompass a significant number of crowns in a reasonable amount of time and to  minimize the variance in nominal point density between the ground and the tree top. The point density required for the study of such enormous plants is much lower than that required for a single grape vine, where a researcher may be interested in the orientation of individual leaves. To characterize the structure of a grape vine, point density must be suitably high, which, using the same instrument as used for the old growth, requires a lower flight elevation. However, if the vinyard is situated in a valley with considerable relief, the variance in point cloud density at a constant geodetic elevation will reduce the point density in lower-elevation sectors of the study area. This effect is proportionally larger at lower elevations.

It is important to note, here, the distinction between terrain elevation and surface elevation. A study using LiDAR may be concerned with the morphology of the terrain itself, or with objects on the terrain, such as plants and buildings. Whether the instrument's elevation follows the terrain, or the surface, which includes such objects, is decided by the purpose of the campaign. If the goal is to study objects on the terrain, it is usually desireable to maintain the platform's elevation with respect to the surface elevation, for example a forest canopy. If the subject of study is the terrain itself, the elevation should be maintained relative to it. The latter case introduces the problem of obstacle avoidance and object identification. For example, it must be determined whether an increase in terrain elevation is due to the appearance of a vegetative canopy or an actual up-slope in the terrain. If the former is true, and the platform is following the terrain elevation, it must be configured to avoid colliding with the trees.

Point density and flight-line overlap are manageable, then, so long as the variation in platform elevation relative to the subject is minimized. There are two ways to accomplish this: First, by rasing the platform to a sufficient elevation to minimize the variation in point density; second, by following the terrain at a constant relative elevation. This research is concerned with the latter option.

\subsection{Hyperspectral Imaging}

A hyperspectral sensor, or imaging spectrometer, is a passive sensor that measures reflected light in very narrow frequency bands. Some such scanners can record over 400 distinct spectra. There are two primary types of hyperspectral sensor, the push-broom scanner, which is an array of sensor elements oriented across the scanning direction, and the whisk-broom scanner, in which an array of elements aligned with the scanning direction sweeps side-to-side across it \cite{Lillesand1999}.

The advantage of a hyperspectral scanner over a multi-spectral scanner, such as the Landsat Thematic Mapper, is the narrow width of its spectral bands. For example, band 7 of the Landsat TM instrument is $0.27\si{\um}$, while a typical hyperspectral scanner will record bands of $0.01\si{\um}$ in width \cite{Lillesand1999}. Just as a high spatial resolution reduces the mixing of spectra in a pixel, a high spectral resolution reduces mixing within spectra. If, for example, there is an absorbtion feature somewhere within Landsat's band 7, it will be impossible to discern. A collection of narrower  bands across the same span of wavelengths will be able to resolve the feature.

A major issue with all spectrometers is the interaction between light and the atmosphere. The ultimate goal of spectometry is to determine the reflectance of a surface, which is presumed to correlate with some characteristic of or process within the underlying object. In a vacuum, reflectance is simply the ratio between irradiance (energy from the source) and radiance (energy reflected from the subject). However, under natural conditions, the spectrometer measures radiance from the subject plus enery reflected from the atmosphere between the sensor and the target (path radiance). Irradiance is then the sum of attenuated light sources, generally the sun and incident radiation from the atmosphere \cite{Lillesand1999}. Unfortunately, these atmospheric effects cannot be ignored, even at the low elevations flown by UAVs. However, the variations can be minimized by maintaining a constant elevation and thus a consistent volume of atmosphere between the sensor and the subject.

Platform elevation has several effects on hyperspectral data quality aside from atmospheric effects. The first of these is the effect on resolution, as discussed above: As the platform elevation increases, the sensor's spatial resolution -- that is, its ability to resolve discrete objects -- declines, resulting in spectral mixing within pixels. Another effect is on the ratio of signal to noise. Each element of a hyperspectral scanner captures a discrete value by recording incoming radiation for a specified interval, called the intergration time. For a given platform velocity and integration time (which are set during the planning phase of the mission), the amount of energy received by an element is proportional to the area of visible reflective surface, which is in turn proportional to the platform's elevation. Since the instrument noise is constant, the reduced proportion of incoming energy reduces the signal-to-noise ratio. In order to maintain this ratio despite variations in elevation, the platform must either adjust its speed, which has other undesireable consequences, or the sensor's integration time, which is not possible or desireable in real time. The integration time has consequences with respect to vehicle velocity as well. When the sensor is active, it smears across the target for the duration of its integration time. So long as the velocity is constant and pitching movements are minimized, this effect is constant.

\subsection{Terrain Following}

The quality issues highlighted in previous sections can be addressed, to an extent, through careful control of the platform's elevation, which should remain constant relative to the surface of interest. The axial movements of the platform should also be minimized. However, unlike a fixed-wing aircaft and helicopters, which maintain the attitudes of their chassis using control surfaces and tilting rotors, respectively, a mutli-rotor UAV moves by coordinating the differential thrust of its fixed rotors to rotate its chassis. This poses a unique challenge for the autonomous control of UAVs used in remote sensing. It is important to note that, in remote sensing applications, the surface to be followed may or may not be terrain \emph{per se}, so the more general term, "surface," may be substituted.

When a UAV encounters a change in surface elevation it must adjust its vertical trajectory. Due to the inertia of the platform, the change in velocity is necessarily delayed until some time after the vehicle's thrust and attitude have been adjusted. It is thus impossible for a vehicle to follow a terrain exactly using a purely reactive system without backtracking. This situation pertains when the vehicle's rangefinder is oriented to nadir. Trivially, if the vehicle approaches a vertical face and is not capable of sensing forward, it will contact the face.  Alternatively, the vehicle may have the ability to sense changes in surface elevation some distance ahead in the direction of travel. Should it encounter a vertical face, it can take evasive action.

In a naive approach to the problem, should the vehicle approach a vertical obstacle, its horizontal velocity must drop to zero and its vertical velocity must increase from zero. This is undesireable in a remote sensing context as, during the deceleration, the sampling density will increase until, during the ascent, the instruments will continue to sample the same ground repeatedly. After the ascent, there will be a brief flight over a surface at the original elevation while the vehicle is at the new elevation. Scale distortion in this region will be maximized. Also at this time, the vehicle will begin accelerating in the horizontal direction again, with gradually-decreasing over-sampling over the elevated surface. These anomalies will have to be rectified in post-processing, if possible. This strategy also entails a considerable increase in flight time. Alternatively, the vehicle can follow a smoothed trajectory which departs from the nominal flight elevation but preserves the vehicle's horizontal velocity (figure \ref{fig:uav_smooth_traj}). In this case, scale distortion is induced in the data, but the along-track sampling density remains constant.

There are mechanisms for enabling terrain following for UAVs which depend on the pre-existence of a digital surface model (DSM). This has two consequences: first, that the survey must have been performed previously and the resulting data processed into a DSM; second, that the DSM must be of sufficient quality, accuracy and detail to control the UAV safely and accurately enough to satisfy the data-quality demands of a remote sensing campaign, given the nature of the terrain, ground cover and the desired flight elevation. Currently-available solutions use the Shuttle Radar Topography Mission (STRM) elevation model, which is one of few freely-accessible global digital elevation models (DEMs), but is not a true DSM; C-band RADAR may penetrate up to half way through a forest canopy \cite{Carabajal2005} and will penetrate into snow, depending on its porosity and wetness \cite{Tighe2009}. The maximum resolution of the SRTM DEM is $30'$ (approximately $30\si{\m}$) horizontally and $1\si{\m}$ vertically, with stated vertical accuracy of $\leq16\si{\m}$, much too coarse for low-elevation remote sensing work, particularly in steep or forested terrain.

An ideal solution would be for the UAV to compute a surface model on its own, in real time, and follow the surface at a fixed elevation while executing its flight plan. The point cloud generated by a forward-facing laser may be contributed to that of the downward-facing main LiDAR, both to densify it and to contribute views of the subject from fore and aft, rather than only left and right, as is typical. 

\begin{figure}
\centering
\def\svgscale{0.5}
\input{build/images/uav_smooth_trajectory.pdf_tex}
\caption{Zero-velocity and smoothed trajectory adjustments. Black arrows indicate regions of scale distortion. Dashed arrows indicate regions of over-sampling due to changes in horizontal velocity.}
\label{fig:uav_smooth_traj}
\end{figure}

The problem of platform stability during elevation adjustments is complex. A hovering UAV requires an amount of thrust (measured in Newtons, $N$) equal to the downward force on the vehicle, given by

\begin{equation}
f = ma,
\label{eq:hover_force}
\end{equation} where $f$ is the downwad force, also in Newtons, $m$ is the mass of the vehicle in kg, and $a$ is the acceleration of gravity on Earth, approximately $9.8m/s^2$. A UAV moving forward at a steady velocity requires an amount of thrust equal to the hovering thrust plus an additional force to maintain altitude while it moves horizontally. This is given by,

\begin{equation}
v_i = \dfrac{ v_h^2 } { \sqrt{ (v_\infty \cos \alpha)^2 + (v_\infty \sin \alpha + v_i)^2 } } ,
\label{eq:move_force}
\end{equation} where $\alpha$ is the angle of attack, $v_\infty$ is the free stream speed (platform velocity plus wind) and $v_h$ is the hover velocity \cite{Hoffmann2007}. If the maximum available thrust of the platform is known, this provides an approximate limit on the rate of climb acheivable by the vehicle, which, in turn, places limits on the amount of advance warning required by the vehicle for a given change in elevation.

With a forward-facing rangefinder, the problem of an approaching obstacle is easily resolved, but descending presents another problem. As the vehicle approaches the lip of a cliff, the terrain below the face is occluded by its edge (figure \ref{fig:uav_edge_occlude}) depriving the vehicle of elevation information that it needs to optimize its trajectory. With a single-beam rangefinder, at one timestep, the lip will be sampled, and at the next, the ground will be sampled. The vehicle can estimate the terrain as the convex hull of these elevations and derive a trajectory based on this modelled terrain, but it cannot revise this estimate or its trajectory without a rangefinder with a broader vertical field of view, or one or more additional ragefinders directed downward at a steeper angle. A similar phenomenon occurs when the vehicle is traversing down a slope that does not intersect with the rangefinder's beam. If the end of the slope is beyond the instrument's range, the vehicle loses contact with the ground and has no information from which to compute a trajectory.  Ideally, the vehicle could have a sensor that is sensitive from nadir to the horizon, and adjust its trajectory iteratively as it approaches the edge. 

\begin{figure}
\centering
\def\svgscale{0.8}
\input{build/images/uav_edge_occlude.pdf_tex}
\caption{Rangefinder occlusion on obstacle edge.}
\label{fig:uav_edge_occlude}
\end{figure}

To identify a sufficient advance angle for a forward-facing rangefinder, it is necessary to first calculate the time reqired for a UAV to change its velocity. At the extreme, in the case of the vertical cliff of indeterminate height, this is the time required to reduce the vehicle's horizontal velocity to zero. It would be a simple matter to calculate the time required for the vehicle to decelerate given its mass, available thrust, velocity and environmental conditions. However, owing to the fact that a multi-copter must control its speed by pitching, which should be minimized to protect data quality, the rate of deceleration should be carefully considered. On the other hand, if the horizontal distance dedicated to ascending is to be minimized (to minimize the horizontal distance affected by scale distortion), the vehicle's maximum thrust must be considered --- it must be able to ascend rapidly enough to clear the terrain without losing horizontal velocity.

Research into terrain following has been continuing since the 1960s for the control of ballistic missiles and jet aircraft \cite{KRACHMALNICK1968,Starling1971,Cunningham1980}. Such systems use a forward- and downward-facing RADAR rangefinder to detect the terrain elevation some distance ahead of the vehicle, some means of terrain classification \cite{Cunningham1980}, and a method of altering the vehicle's trajectory to follow the terrain surface as closely as possible. Research on terrain following for military aircraft and missiles has been focused on high-speed, low elevation flight with a premium placed on stealth, speed, efficiency and safety \cite{KRACHMALNICK1968}. It is important to note the distinction between terrain following and terrain avoidance, here: terrain avoidance involves changing the trajectory of the vehicle, vertically or horizontally, in order to avoid terrain; terrain following implies the maintenance of a minimum distance to the terrain, but also a maximum distance. Missiles and military aircraft must fly low to avoid detection by radar and interception by surface-to-air or airborne weapons. Neither high speed nor stealth are desireable for a remote sensing mission but many of the insights from this research are nevertheless applicable to remote-sensing UAVs.

The key feature of these terrain following systems is their predictive, rather than reactive, nature. Most existing UAV terrain following systems have used either a nadir-aligned rangefinder and a feedback loop for adjusting the vehicle's elevation to a predetermined value in real time \cite{ArduPilot2017}, or a pre-exiting elevation model which is interpolated to generate a three dimensional flight path \cite{ArduPilot2017,Samar2011}. Military terrain following systems provide both the ability to adaptively respond to terrain without pre-planning, and the ability to optimize their flight plans in flight with some degree of foresight. 

For example, Starling \cite{Starling1971} envisioned a RADAR-based system featuring a virtual "ski" sliding on the terrain ahead of, and in alignment with, the aircraft. As the ski encountered a rise, its axis would intersect that of the aircraft, generating a climb-command, causing the aircraft to climb. As the ski rode the terrain down again, the axes of the aircraft and the ski would diverge, generating a descend-command. This feature had the valueable quality that on low-frequency terrain, the aircraft would follow it closely. On high-frequency terrain, the aircraft woud tend to smooth the terrain, following a trajectory that would not exceed the gravitational tolerances of the pilot (about 1g). Several authors (\cite{MENON1991,Popovic2017,Lu1995,Rahim2011,Samar2011}) suggest the use of polynomial splines for developing smoothed trajectories from terrain elevations, and Lu and Pierson \cite{Lu1995} documented a method for terrain-following in a fixed-wing aircraft by exploiting the lift and drag properties of the vehicle and "bang-bang" (on/off) throttle control. 

None of these strategies are ideal for remote sensing UAVs. In the first and second instances, maintaining a constant elevation with respect to terrain immediately below the vehicle is not the rsearchers' primary concern. In the third, reliance on the aerodynamic lift of the craft to smooth elevation changes in a power-off situation is a non-starter, as multi-copters have essentially none.

Alqahtani and Emron \cite{Alqahtani2018} devised a system using using downward- and forward-facing rangefinders with a Gaussian surface filter with various window sizes to anticipate terrain undulations and project a forward trajectory. This research generated some important insights and resolved some of the issues highlighted at the beginning of this section. The authors found that, though a small Gaussian window would enable the vehicle to follow terrain closely, it would also cause the vehicle to hit large obstacles if the laser were not aimed high enough. The occlusion problem (figure \ref{fig:uav_edge_occlude}) could be resolved, in part, by reducing the Gaussian window dynamically according to the orientation of the terrain surface. The authors found that this strategy could reduce the vehicle's power consumption by eliminating hard transitions in and out of the altitude control loop.

The use of a three-dimensional point cloud and ground classification algorithms do not seem to have not appeared in the literature on UAV terrain following, perhaps because LiDAR devices small enough for use on such vehicles are a recent innovation. While Alqahtani and Emron did not address the use these devices, their work nevertheless provides a valuable starting point for research in this area. 

\iffalse

*** The power required by the vehicle following any trajectory can be calculated by taking the integral of the function decribing the thrust or power curve. This curve will be something like figure \ref{fig:uav_power_curve}.


\begin{equation}
T_d = \dfrac{v}{\sin(\theta) * E}
\label{eq:decel}
\end{equation} 

\begin{figure}
\centering
\def\svgscale{0.8}
\input{build/images/uav_power_curve.pdf_tex}
\caption{The power curve of a terrain-following event.}
\label{fig:uav_power_curve}
\end{figure}

\fi

\subsection{Rangefinder and Algorithm Selection}

The success of a surface-following application depends on the ability to accurately locate the terrain with respect to a moving vehicle. There are many instruments capable of providing this service, including RGB cameras, lasers, sonar devices and RADAR. Laser and camera rangefinders are considered here.

\subsubsection{RGB Camera}

A digital RGB camera with a wide-angle lens will cover a wide field of view at high resolution and reasonably low cost relative to other instruments, but will require computationally-intensive photogrammetry or optical-flow processing to extract range measurements \cite{Campos2016,Herisse2010,Netter2002,Hammoud2011}, though, as noted by Campos \cite{Campos2016}, the most processing-intensive step in this process may be the image encoding. In general, the quality and resolution of a camera are proportional to its cost and weight. Also, spectrometers are passive sensors, meaning they record reflected light from variable environmental sources, specifically the sun, and are thus subject to weather conditions and the availability of daylight. Tracking changes in intensity or colour across the pixel array becomes difficult without the consistency of a controlled energy source or on low-contrast and complex surfaces, hampering the detection of objects which would be used to compute ranges. 

Optical flow is a method that attempts to estimate the structure of a three-dimensional space by tracking the changes in position of objects within the space, as projected into two-dimensional space (the image itself). The motion of objects is represented in the image as changes in intensity of pixels within the pixel array. This method works only when the camera motion, hence platform velocity, is sufficient to induce detectable changes in the pixel array during the required time interval, and may fail when the magnitude of change exceeds a reference value \cite{Srinivasan1994}. Optical flow works best over planar terrain, with errors of up to 10\% \cite{Campos2016} on more complex surfaces. Also, platform rotation can interfere with the accuracy of range measurements and the penetration of porous surfaces, such as forest canopies is not possible. Indeed, such surfaces may confuse the algorithm. Interestingly, in studies of photo-flow for use in UAV terrain following, single-beam laser rangefinders mounted with the camer are often used for validation \cite{Campos2016}.

Photogrammetry is a method using parallax to generate a point cloud from sequential image frames \cite{Carrivick2016}. These points may then be used as if they were generated by a scanning LiDAR, however this method suffers from many of the same limitations as optical flow.

\subsubsection{Single-beam Laser Rangefinders}

One or more single-beam laser range finders can be mounted statically (per \cite{Alqahtani2018}), on a scanning gimbal \cite{LightWare2017} or in a mixture of configurations. These instruments use the time-of-return of a pulse of laser light to calculate the distance to a reflector. This distance must be transformed, if desired, into a polar or Cartesian coordinate by an external computer. Laser rangefinders are active scanners that emit their own energy, so they are less dependent on environmental conditions and scene contrast for measurement accuracy, however measurement density with respect to time may be reduced by scattering, absorbtion or reflection on some surfaces, such as water which both reflects and absorbs light at the typical wavelength of $\sim1000\si{\nm}$. These devices are cheap and light but do not offer the spatial coverage of either a digital camera or a scanning LiDAR, making the intelligent analysis of terrain conditions an   d ground cover --- as opposed to the simple elevation --- difficult. However, they are highly accurate within their nominal range \cite{Campos2016} and the type and volume of data they produce is fairly trivial to process using a Gaussian \cite{Alqahtani2018}, Kalman \cite{Kalman1960} or other smoothing regime. High-qality versions of these instruments produce over 18,000 pulses per second at accuracies of $\pm10\si{\cm}$ or better \cite{LightWare2016}.


\subsubsection{Scanning LiDAR}

Scanning LiDAR devices --- whether spinning or oscillating mirror type, rotating single- or multi-beam or solid state --- provide scene coverage second only to that of a digital camera and, being active sensors, suffer less from the influence of environmental conditions. These are heavier than other options, consume more power, and produce a large enough volume of data that processing can be complex and time consuming, but they resolve most of the problems inherent in digital cameras and single-beam rangefinders. With a high-enough scanning frequency, the servo-mounted single-beam laser could be included in this category.

With the advent of automotive multi-beam scanning LiDAR devices, a unique opportunity arises. Unlike traditional scanning LiDARs, these devices produce multiple, simultaneous scan-lines over an arc from $30\degree$ to $40\degree$. By tilting these instruments slightly forward, they can serve as both the main remote sensing instrument, and the the terrain following sensor, and can provide sufficient point density and coverage for extremely accurate real-time terrain characterization. For a vehicle flying at 35m elevation, a LiDAR scanning $30\degree$ forward offers approximately $20\si{\m}$ of advance coverage, or $4\si{\s}$ at $5\si{\m\per\s}$. 

With the dense, three-dimensional point clouds produced by scanning LiDARs, there arises the opportunity to characterize terrain features in a way that is impossible with other methods. This is due in part to the distribution of points and to their number. If the space under examination is discretized into useable parcels, there are enough measurements in each to perform a robust statistical analyisis and classification of the features that lie therein. There are many methods for analyzing dense point clouds, removing noise and classifying objects, but it is important to remember for this research that the object is less the accurate classification of ground cover and more the rapid determination of a safe and accurate trajectory.

A Cartesian LiDAR-derived z-coordinate is composed of three elements, 

\begin{equation}
E_{sensor} = E_{ground} + E_{non-ground} + M_{noise},
\label{eq:decel}
\end{equation} 

where $E_{sensor}$ is the measured height, $E_{ground}$ is the true ground elevation, $E_{non-ground}$ is the height of objects on the ground, and $M_{noise}$ is measurement error, which may arise from a variety of sources \cite{Meng2010}. The various classification methods interact with different parts of this triad, with different goals. Isolating the terrain elevation may be a simple case of marking all last-return points points as ground, and then removing outliers according to specified criteria. Though objects on the terrain are often penetrable by the laser and therefore distinguishable from terrain, the opposite is sometimes true. When such objects are opaque, a more sophisticated method must be used to isolate and identify them.

Motivated by Tobler's principle, in which objects nearer to each other in space are likely to be more similar, Vosselman \cite{Vosselman2000} proposed a method whereby the slope measured between two adjacent points could determine, based on a threshold, whether both were ground, or one was non-ground. In this case, the threshold angle would be determined by the scale of measurement and the nature of the environment. For example, a very low threshold angle would detect a person standing on a football field, while it would take a significantly higher angle to detect the same person on a steep slope. Also in the Toblerian vein, Khosravipour \cite{Khosravipour2016} used the "spikiness" of facets in a triangulated irregular network (TIN) of LiDAR points to idenitfy points that did not belong to the terrain surface; given the presumption of regularity in the distribution of points in the horizontal dimensions, an overly accute angle in any facet could likely be caused by an extreme in the vertical dimension. 

The progressive morphological filter \cite{Zhang2003} uses a progressively-opening "window," within which the minimum-elevation point is selected, to iteratively distinguish ground points from objects. Chang \emph{et al} \cite{Chang2008} used the detection of occluded --- that is, empty --- regions in an oblique scan to identify and filter non-ground points, and there are other methods using thin plate splines \cite{Hudak2012}, Hermite splines \cite{Silvan-Cardenas2006} and others \cite{Hodgson2005,Zheng2007,Zhang2005}.

These methods have in common single object of accuracy with respect to the true terrain elevation and the identification of points that are representative of terrain. For the purposes of terrain following, accuracy and object identification are less important than efficiency and safety. To determine the correct flight elevation over terrain, the UAV needs a reasonably accurate representation of the elevation, excluding objects such as plants and vehicles, for example, but the respresentation will be smoothed as it is developed into a trajectory so absolute accuracy is relatively unimportant. For vehicles that must follow the surface, which includes the vegetative canopy or buildings, the vehicle need not perform any classification at all, only remove points suspected of being noise and develop a smooth trajectory over the rest. This considerably simplifies the task of developing the surface model.

One possible solution is to store all LiDAR points during a time interval into a grid of lists, with each list representing a column with a predetermined spatial extent. At the end of the interval, the mean of a selected quantile will be used as the elevation --- a high quantile for a forest canopy, for example, and a low quantile for terrain.


\iffalse


\subsection{SLAM}

Simultaneous localization and mapping.

Traditional terrain-following mechanisms used RADAR for measuring the distance from aircraft to terrain. The advent of cheap, lightweight LiDAR instruments, primarily designed for the autonomous vehicle market, has made available 


The Kalman Filter \cite{Kalman1960} is a recursive least-squares optimizing function that effectively converges on a true value -- in one or more dimensions -- at each time step by assigning a weight to the current state and the inputs depending on the confidence in each, and generating a new state estimate which will be subjected to the same process on the next time step. A primary consideration in the development of state-space smoothing methods such as Kalman's is the impossibility of storing a complete history of the object's state and estimating its immediate future based on its entire past. The latter would entail an ever-increasing processing load, as the object's history grew. Another consideration is the temporal variability in the certainty of new estimates of the object's state (i.e. measurements). As these vary through time, they would also have to be stored and computed to derive an estimate of the object's state. The Kalman filter solves these problems by considering only the object's present state, the inputs, and an error estimate for each \cite{Swerling1959}. 

Kalman filtering was originally used for estimating the trajectories of the Apollo lunar landers and for RADAR tracking of targets \cite{Grewal2010}, but is widely used in climate science, econometrics, engineering, especially in the field of robotics. Autonomous robots, UAVs included, must have reliable information their position, orientation and velocity in order to interac effectively with the environment. Airborne vehicles, in particular, must have accurate information about their position and orientation, but also their trajectory.

A typical UAV uses the Global Positioning System (GPS) for absolute positioning and an inertial navigation system (INS) for measuring acceleration and orientation. These inputs together allow the vehicle to ajust its attitude and velocity to maintain a pre-defined trajectory, and -- arguably, more importantly -- for georeferencing collected data. There are numerous sources of measurement error inherent in GPS and INS measurements which hamper the vehicle's ability to ascertain its instantaneous state; the Kalman filter provides a means of determining its true state with a high degree of confidence.

[Extended Kalman filter -- local linearization?]

\fi

\subsection{Mission Planning}


For remote sensing surveys using UAVs, missions are generally not flown manually by the pilot, but planned using software that lays out a regular grid of flightlines optimised for data resolution and flight line overlap. However, these mission plans are two-dimensional only, and must be augmented by an auxiliary terrain-following process. One such software product is Maps Made Easy, which produces flight plans for popular UAVs made by the DJI company.

\section{Methods}

\subsection{Simulation}

Given the number of available laser scanner types and configurations, ground classification routines and trajectory methods and the variety terrain and ground-cover types a UAV may encounter, it will be prudent to execute computerized simulations of a number of permutations before acquiring hardware and performing flight tests. Several rangefinder configurations are listed in figure \ref{list:rangefinder_configs}. 

\begin{table}
\caption{Rangefinder configurations.}
\label{list:rangefinder_configs}
\begin{tabular}{r | l}
\hline
1 & Single-beam, single-return. \\
2 & Single-beam, multi-return. \\
3 & Single-beam, single-return with a servo driver for mechanical, side-to-side scanning. \\
4 & Split-beam, multi-return, solid-state. \\
5 & Multi-beam, multi-return, solid-state. \\
6 & Single-beam, multi-return, spinning laser. \\
7 & Single-beam, multi-return, spinning mirror. \\
9 & Single-beam, multi-return, oscillating mirror. \\
10 & Multi-beam, multi-return, spinning laser. \\
\hline
\end{tabular}
\end{table}


The output of any rangefinder can be simulated by defining a terrain-generating function and sampling it at positions that would be read by the instrument. Gaussian noise can be applied to the samples simulate measurement error using the characteristics documented by the manufacturer or testing. In a real-world scenario, it would be neccessary to account for uncertainty about the vehicle's elevation and the actual elevation of the terrain. In a simulated environment these can be controlled, leaving only the optimality of the trajectory to be assessed.

Figure \ref{fig:point_plane} shows an example of the output of a hypothetical regular sampling of a planar surface. The first plot shows the outcome using measurements with zero uncertainty. In the second and third images, the measurements are perturbed by random Gaussian noise with standard deviations of 0.001 and 0.01, respectively, to simulate error. Single-beam rangefinders may be mounted statically (figure \ref{fig:linear_plane}) or on a servo, which scans back and forth across the terrain in a sinusoidal fasion (figure \ref{fig:sinus_plane}). A list of possible surface types can be found in figure \ref{list:ground_types}. These lists are not exhaustive. 


\begin{figure}
\centering
\def\svgscale{0.25}
\input{build/images/plane_grid_0.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_grid_0001.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_grid_001.pdf_tex}
\caption{Simulated grid sampling of planar surface with Gaussian error; $\sigma 0$, $\sigma 0.01$ and $\sigma 0.001$.}
\label{fig:point_plane}
\end{figure}

\begin{figure}
\centering
\def\svgscale{0.25}
\input{build/images/plane_sinus_0.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_sinus_0001.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_sinus_001.pdf_tex}
\caption{Simulated sinusoidal scan of planar surface with Gaussian error; $\sigma 0$, $\sigma 0.01$ and $\sigma 0.001$.}
\label{fig:sinus_plane}
\end{figure}

\begin{figure}
\centering
\def\svgscale{0.25}
\input{build/images/plane_linear_0.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_linear_0001.pdf_tex}
\def\svgscale{0.25}
\input{build/images/plane_linear_001.pdf_tex}
\caption{Simulated linear scan of planar surface with Gaussian error; $\sigma 0$, $\sigma 0.01$ and $\sigma 0.001$.}
\label{fig:linear_plane}
\end{figure}

\begin{table}
\caption{Surface generation methods.}
\label{list:ground_types}
\begin{tabular}{r | l}
\hline
1 & Planar. \\
2 & Continuous non-planar functions \\
3 & Planar and functional surfaces with geometric objects \\
4 & Surfaces reconstructed from existing LiDAR \\
\hline
\end{tabular}
\end{table}

Figure \ref{fig:plane_object} shows the expected result of scanning a plane with a square object using a grid, sinusoidal scan and linear scan from a nadir-aligned instrument.

\begin{figure}
\centering
\def\svgscale{0.25}
\input{build/images/block_grid_0.pdf_tex}
\def\svgscale{0.25}
\input{build/images/block_sinus_0.pdf_tex}
\def\svgscale{0.25}
\input{build/images/block_linear_0.pdf_tex}
\caption{Simulated scans of planar surface with obstacle.}
\label{fig:plane_object}
\end{figure}


Trajectory-extraction methods are listed in figure \ref{list:traj_methods}. The absolute offset trajectory is used as a control of sorts because, under this regime, the vehicle will behave as if it had a nadir-aligned rangefinder and the ability to react instantaneously to fluctuations in the surface elevation, an event that would create discontinuities in the power curve or cause collisions with steep slopes. The ground classification methods  (figure \ref{list:class_methods}) also feature a control in the form of non-classified point stream. In the case of \cite{Alqahtani2018}, for example, this is expected, however it will be interesting to record whether ground point classification and outlier filtration have any meaningful effect on the trajectories.

\begin{table}
\caption{Trajectory-finding methods.}
\label{list:traj_methods}
\begin{tabular}{r | l | c}
\hline
1 & Absolute offset (control) & \\
2 & Gaussian smoothing & \cite{Alqahtani2018} \\
3 & Hermite spline &  \cite{Silvan-Cardenas2006} \\
4 & Thin-plate spline & \cite{Hudak2012} \\
\hline
\end{tabular}
\end{table}

\begin{table}
\caption{Ground point classifiers.}
\label{list:class_methods}
\begin{tabular}{r | l | c}
\hline
1 & None (control) & \\
2 & Quantile filtering & \\
3 & Slope-based & \cite{Vosselman2000} \\
4 & Progressive morphological filter & \cite{Zhang2003} \\
\hline
\end{tabular}
\end{table}


The point pattern of any of these instruments can be generated at any density with a variety of error characteristics using a simple program. The code in listing \ref{fig:scan_code}, for example, generates a sinusoidal scan along a plane with a scan frequency of $2\si{\Hz}$ and pulse frequency of $200\si{\Hz}$ and a configurable error term for each dimension. Knowing that the elevation of the plane is a constant, zero, one can reverse-engineer the error characteristics of the virtual instrument used to generate this scan. Simulated terrains may also be generated from existing LiDAR scans of real-world environments and re-scanned using the virtual scanners. 

\begin{figure}
\begin{lstlisting}
theta = 0     # scan angle
time = 0      # current time step
x_range = 50  # scan width in x
y_speed = 0.1 # speed in y per time step
while True:
	x = sin(theta) * x_range + error(0.05)
	y = time * y_speed + error(0.05)
	z = error(0.1)
	theta += PI / 2 / 100
	time += 1
	sleep(5)
\end{lstlisting}
\caption{Simple script for generating sinusoidal scan. Error function returns a Gaussian with the given standard deviation.}
\label{fig:scan_code}
\end{figure}

The steps for each simulation trial are listed in figure \ref{fig:traj_sim}. The final step, assessing the quality of the trajectory, must respect some specific constraints. First, it should follow as nearly as possible the modelled surface. This can be measured using the sum of least squares of differences between the trajectory and the surface. The fact that the trajectory follows the surface closely does not mean that the vehicle will be able to follow the trajectory, nor that if it does so successfully, it will do it efficiently. Since the trajectory is modelled as a sequence of line segments, the physics of a vehicle may be approximately modelled given the state (i.e. velocity vector) of the vehicle at the start of the segment and the slope of the current segment. Given this information it will be possible to model the thrust required for the vehicle to follow the trajectory. If the thrust is within the vehicles nominal limits, the traversal will be considered successful. Given that vehicle power consumption is proportional to its thrust, it will be possible to model the power consumption of the vehicle by minimizing the integral of its thrust curve over the length of the trajectory. Since the trajectory is represented as a line string, rather than a continuous function, for practical reasons, it will suffice to calculate the power consumption by summing the area under each segment of the power curve.

\begin{enumerate}
\item Configure surface model.
\item Generate point cloud from modelled surface using pre-determined error parameters.
\item Classify ground points (optional).
\item Classify non-ground points (optional).
\item Select points for trajectory computation.
\item Compute trajectory.
\item Assess trajectory quality.
\label{fig:traj_sim}
\end{enumerate}

Ultimately, each step in the simlation (figure \ref{fig:traj_sim}) will be represented by such a program. Chained together, they will produce a numerical assessment of the quality of the instrument and algorithm selection with respect to data quality and power consumption.


\bibliographystyle{plain}
\bibliography{/home/rob/Documents/bibtex/library.bib}


\end{document}