\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{gensymb}
\usepackage{siunitx}
\usepackage{setspace}	% for line spacing
\usepackage{calc}		% for figure scaling
\usepackage{svg}		% for graphics
\usepackage{graphicx}	% for graphics
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}
\usepackage{listings}

\linespread{1.5}

% Images are build by calling images/generate.sh <images> <output> where
% output is the "build" directory used by Texmaker.
\graphicspath{{./build/images/}}
\DeclareUnicodeCharacter{2010}{ }

\author{Rob Skelly}
\title{Literature Review}

\lstset{%
  basicstyle=\small\ttfamily,
  language=Python
}

\begin{document}

\maketitle

\begin{abstract}
etc...
\end{abstract}

\section{Introduction}

Unmanned aerial vehicles (UAVs) are small reusable aircraft, controlled remotely by a human operator or (semi-)autonomously. they are presently the subject of an explosion in engineering, scientific, military and commercial interest. UAVs can range in size from insect-scale to jet-powered military aircraft. Military interest in UAV research is a given, and indeed drives much of the research into the development of related technologies, but the emergence of an entrepreneurial just-build-it technological culture and the ability of firms to design and produce highly sophisticated, miniaturized components and high-capacity, lightweight batteries, has enabled basement tinkerers, commercial startups and academics alike exploit the capabilities offered by UAVs, rapidly and at little cost.

In the scientific remote-sensing field, where the execution of an aerial survey could entail hundreds of thousands of dollars in costs for planning, permitting, instrumentation, pilots and aircraft, the advent of UAVs provides researchers with the opportunity to conduct research at much lower cost with little turnaround time. 

Naturally, there are compromises to be made between traditional aerial remote-sensing and the use of UAVs. UAVs tend to be limited to low elevations, short flight times and small site sizes. The instrumentation -- specifically multi- and hyperspectral imagers and LiDAR -- has only recently achieved a level of quality sufficient for research and form factor small and light enough for inclusion on a UAV. Additionally, many of these instruments are designed for uses other than remote sensing, in particular LiDAR devices, which are often designed for the automotive market. However, with the drawbacks come advantages. The level of detail attainable with a low-elevation UAV survey would be impossible with a traditional aerial campaign and the cost, danger and disruption of a traditional campaign could be prohibitive.

Traditional aerial surveys have the advantage that, at typical survey elevations of $\SI{250}\m-\SI{1000}\m$, variations in terrain elevation are insignificant, relative to the overall elevation -- except in extreme cases, such as alpine terrain -- with minimal scale distortion in the resulting imagery. Low-elevation UAV surveys, which may take place at $\SI{10}\m-\SI{50}\m$ elevation above the surface, encounter much larger relative variations in terrain elevation and so must follow the terrain, both to maintain the scale and quality of the data they collect, and to avoid colliding with it. In addition, because there are many structures, both natural and manmade, that may project above the elevation of the UAV's trajectory, the vehicle must have the ability to detect and avoid hazards. Manned aircraft, with an alert pilot and high elevation, rarely face such obstacles.

So, in order to use a small, low-elevation UAV for remote sensing, the vehicle must be capable of maintaining a constant elevation of flight above the terrain. Because the pilot cannot be present to monitor the terrain ahead of the vehicle, make desicions about what the terrain \emph{is} (the forest canopy? the ground?) and whether it should be followed, calculate a trajectory and adjust the altitude to follow it, an autonomous terrain-following control system is required.

The justification, design and construction of such a system touches on many different fields in remote-sensing, earth science and engineering. The principle topics covered here are as follows:

\begin{enumerate}
\item Ethics
\item Remote Sensing
\begin{enumerate}
\item Data Quality
\end{enumerate}
\item Trajectory Estimation
\item Surface Reconstruction
	\begin{enumerate}
	\item Computational Geometry
	\end{enumerate}
\item Control Systems
	\begin{enumerate}
	\item Kinematics and Dynamics
	\item PID Controllers
	\end{enumerate}
\end{enumerate}


This review will summarize research into a variety of disparate fields, insofar as they contribute to the development of the terrain-following system. This will include academic research into the topics previously discussed, as well as books and more informal sources of insight, where available.


\section{Ethics}

Clearly, a project that seeks to wrest control from an autonomous aerial platform, with the potiential to harm humans and animals and damage property, must justifiable on ethical grounds. The ``Handbook of Unmanned Aerial Vehicles'' \cite{Valavanis2015j} contains several chapters by different authors on the subject of ethics and autonomous, or semi-autonomous, machines. These are discussed mostly in the context of warfare, using the ethical frameworks developed by scholars of war.

The chapter, ``Ethics and UAVs'' \cite{Valavanis2015bz} begins by addressing the employment of UAVs as weapons. (In this context, UAVs are often pejoratively called ``drones'', to distinguish them from more neutral scientific uses, though the names given to these machines -- ``Predator,'' ``Reaper'' and ``Crusher'' \cite{Lucas2011} -- leave little doubt as to their purpose.) So long as UAVs continue to be controlled, remotely, by a human operator, the ethical landscape remains more-or-less unchanged, versus more hands-on methods of waging war, with several exceptions relating to the feasibility of missions that would not be otherwise possible if an on-site human operator were required. This includes targeted assasinations, which entail the risk of mis-identifying civilians as targets (a possible war crime) and of conducting missions in regions which are not theaters of war. In addition, the accessibility of this technology enables non-state actors (private companies, individuals and militias) to engage in remote warfare \cite[p.2867]{Valavanis2015bz}. 

The inevitable advent of total autonomy muddies the water further: when a machine commits what would otherwise be considered a war crime, who is accountable? Lucas calls this proposition ``preposterous'', arguing that machines are incapable of forming intentions and are therefore incapable of committing crimes \cite[p.2868]{Valavanis2015bz}. This criticism seems to beg the question, however, as a human being \emph{is} a sort of machine and is clearly capable of having intention. Less controversially, perhaps, humans also routinely invest their prejudices into the machines they build \cite{Greenwald1998,Caliskan2017}. 

The chapter becomes a philosophical digressesion into the ethics of autonomous machines but resolves with a meditation on the ethical responsibility of engineers \cite[p.2873]{Valavanis2015bz} revolving around Michael Waltzer's notion of ``double intention'' \cite{Waltzer}. Under this rubric, originally intended to articulate the ethical responsibilities of soldiers, an engineer has the duty not only to \emph{intend} to do no harm, but to exercise \emph{due care} \cite{Lucas2011} -- to take all reasonable steps necessary to ensure that no harm occurs. The chapter ends with an admonishment to engineers to become aware of and center their ethical responsibilities \cite[p.2974]{Valavanis2015bz}.

\section{Remote Sensing}

Simply put, remote sensing is the acquisition of information about an object without the necessity of physical contact between the object and the observer. The human eyes, nose and ears are remote sensing instruments, collecting the electro-magnetic, chemical and mechanical signals that comprise sight, smell and hearing, respectively.

In the geographic and earth sciences, remote sensing is typically (though not exclusively) conducted from above the earth using aircraft or space-borne satellites carrying instruments that measure electro-magnetic or gravitational emissions from the Earth. Electro-magnetic instruments may be further broken down into active instruments, such as light detection and ranging (LiDAR) and radio detection and ranging (RADAR) which emit a pulse of radiation, then measure the temporal delay and intensity of the return; and passive instruments which measure the reflected energy emitted by natural sources such as the sun, or endogenous energy, such as thermal infrared radiation (i.e. heat).

This research considers two types of remote sensing instruments typically used by UAV surveys, a hyperspectral imaging spectrometer (passive) and a scanning LiDAR device (active). 

\subsection{Imaging Spectrometry}

Goetz \emph{et al} \cite{Goetz1985} define hyperspectral imaging spectometry as ``the acquisition of images in many narrow contiguous spectral bands throught the visible and solar-reflected infrared spectal bands simultaneously.'' Narrow spectral bands enable the detection of small absorbtion features which broad-band scanners, such as Landsat, cannot \cite{Geotz1985}. This is particularly important to researchers in agriculture, minerology and other fields where detection of extremely narrow features is necessary \cite{Goetz1985}.

The imaging spectrometers typically mounted on UAVs are of the linear-array ``pushbroom'' type, which have no moving parts and are therefore small and reliable enough for this purpose. In a pushbroom scanner, a single across-track-aligned sensor array moves with the vehicle, with each sensor element receiving photons reflected from the target in a swath perpendicular to the flight path. As the scanner moves across the target, the sensor measures and records radiant intensity in all bands over an \emph{integration time}. During the integration time, all information captured by the element is saved to a single picture element, or pixel, which spatially referenced to the target itself. 

The elevation of the platform above the target determines the across-track (lateral) scale of the resulting image, the forward velocity determines the along-track (longitudinal) scale, and the velocity coupled with the integration time determines the resolution. If the integration time is too short, the scanner will only record within a small portion of the cell. If it is  too long, the cells will ``smear'' together. Most importantly, the integration time and velocity together determine the ``dwell time'' -- the time that a scanner element spends recording any part of the target. As the dwell time increases, the contribution of background (additive) noise, relative to the signal and multiplicative noise, decreases. Thus dwell time is critical to the maintenance of an acceptably high signal to noise ratio \cite{F.MarkDanson1996,Avery1992,Rogass2014}.

These qualities -- scale, resolution, dwell time and signal-to-noise ratio -- are, to some degree, manageble by careful maintenance of platform orientation and target distance. 


\subsection{LiDAR}

DEnsity
Overlap


\subsubsection{Geometric Effects on Image Quality}

[Tangent plane assumption of earth geometry -- ignore geodetic distortions]

``Remote Sensing Geology'' \cite{Gupta2018} provides an extensive survey of the geometric causes of spectral image quality degradation. Geometric causes of degradation are grouped into two categories: systematic and non-systematic. Non-systematic distortions are due to variable or unpredictable factors such as airframe perturbation due to wind, while systematic distortions are those caused by fixed or planned effects, such as sensor-craft altitude and relief displacement.

Some variations in the velocity and attitude of the airframe and instruments are induced by forces (e.g. wind) which are stochastic in time and space and so not easily predicted. Others are induced by phenomena which are stochastic in space but constant in time and therefore predictable. Terrain relief is one of these. Variations in terrain relief induce changes in target distance for a platform and instrument travelling at a constant absolute elevation, which in turn induces geometric distortions. Gupta \cite{Gupta2018} considers these disturbances to be non-systematic, but for the purposes of this research, they will be considered systematic and therefore addressable.

Scale

As the target distance increases, with a constant instantaneous field of view, the surface area of the target captured in a single cell increases. In a digital image, a cell is a region with a constant area and a single value representing a measured value over the target area contained within the spatial extent of the cell. A image, or raster, is made up of a grid of cells. As a cell is the smallest unit that can be discriminated in a digital image, any objects within the cell will be impossible to isolate. Information about discrete objects within the cell is mixed together. As the distance decreases, the target area within a cell decreases, enhancing the contribution of any individual object to the overall cell's value. At a certain point, an object may not fit into a single cell and will occupy, at least in part, several cells. 


, Scale distortions have two important effects on the quality of image data. First, changes in target distance induce changes in image scale and resolution. As the distance increases, the ability of the image to resolve objects of a particular size decreases -- the size of physical objects decreases relative to the size of an image cell. This phenomenon leads to spectral mixing, where radiant intensities of distinct physical objects are mixed within the same image pixel, reducing a researcher's ability to discriminate the phenomena under study.

The most directly addressable non-systematic (or semi-systematic) effect is caused by unwanted changes in platform orientation, specifically pitch. A multi-copter UAV moves horizontally by changing its thrust vector from vertical. Since the rotors are generally fixed to the airframe, the platform itself must assume a non-vertical pose during image acquisition. This is undesireable but unavoidable. However, in order to adjust its altitude or maintain horizontal velocity in the presence head- or tailwinds, the UAV may rotate further, causing geometric distortions in the imagery. 

Mixing and Signal to Noise Ratio

These distortions have two sources, first, the as the vehicle rotates forward on the y (across-track) axis, the ground speed of the scanner footprint slows down. As the vehicle rotates to the rear, the footprint speeds up. This alters the dwell time of the scanner and leads to over- and under-sampling, respectively \cite{Gupta2018}. When he vehicle rotates either to the fore or the rear, the scanner axis rotates away from nadir, increasing its effective footprint, reducing its spatial resolution \cite{Gupta2018} and increasing the effects of spectral mixing. 

An important consequence of variation in dwell time is the effect on the signal to noise ratio. The longer the dwell time, the more light is measured by the instrument relative to the background noise \cite{Rogass2014}.

An optimal trajectory would minimize these rotations, but in the attempt to minimize fore-aft platform rotation, it must be remembered that changes in velocity also affect dwell time.




 \cite{Gupta2018}. 
Quality in the geometric sense is determined by a series of identities relating to the characteristics of a sensor, its orientation, motion, distance from the target and the characteristics of the medium between the sensor and the target.

\cite{Avery2007}
Avery, T. E., \& Berlin, G. L. (2007). Fundamentals of Remote Sensing and Airphoto Interpretation (6th ed.).

Camera viewing angles.
Ground distance


\section{Kinematics and Dynamics}

\subsubsection{Vehicle Dynamics}

\cite{Valavanis2007}

Part II Modelling and Control Fundamentals
Chapter 3: Airplane Basic Equations of Motion and Open-Loop Dynamics

Mostly dedicated to fixed-wing aircraft.
This is a superficial review, though still much beyond the scope of the current project (and way too mathy anyway).
Discussion of position and orientation of platform w/r/t frames (inertial, body, etc.), degrees of freedom, application of Newton’s laws.
Linear approximations of non-linear functions (aerodynamic forces, equations of motion, etc.) in order to make solutions tractable.
Body-fixed reference frame. C is the centre of mass, axis Cx is forward, Cz is down. Right-handed cartesian coordinate system.
Linear velocity components U, V, W, aligned with Cx, Cy and Cz.
Angular velocity components P, Q, R arounc Cx, Cy and Cz.
External aerodynamic forces X, Y, Z along axes. External aerodynamic moments as L, M, N.
Discussion of Euler angles for rotating the body frame relative to its fixed frame. (Twist around the z axis, rotate around y, rotate around z).
Important note that rotation order is important and not commutative.


This is a discussion of the relationships between the coordinate system of the platform and the inertial frame. There is a useful introduction to the way vector addition is used to calculate the displacement of objects relative to each other in three dimensions, and to the way that forces are calculated and transformed between frames. 
For this research, some basic kinematic equations are necessary for calculating the orientation of the rangefinder beam in real-time relative to the inertial frame (i.e. the Earth), given its position relative to the gimbal that creates the scan pattern, and the gimbal’s position relative the the platform and hence the inertial frame. 
The classical mechanics covered here will be necessary to calculate the forces acting on the platform in response to adjustments in the throttle to achieve an optimal (let alone possible) vertical trajectory, for calculating the thrust requirements and hence the power and power consumption.
Small Disturbance Theory - justification for the linearization of non-linear dynamic equations: when 

Chapter 4: Control Fundamentals of Small / Miniature Helicopters - A Survey

Discussion of the reduction in complexity of dynamic/control models to accommodate limited processing power. 
a) Attempt to model dynamics using parameters that represent physical forces; b) Use a reactive “black box” methodology where the parameters don’t model physical properties at all; c) Hybrid between a and b.
Assume “non-aggressive” flight, presumably to avoid control input singularities and exceeding the flight envelope.
Newton/Euler; Quaternions; Energy-oriented approach eg. the Lagrange formulation.

\cite{Kim2004}
Kim, S. K., \& Tilbury, D. M. (2004). Mathematical modeling and experimental identification of an unmanned helicopter robot with flybar dynamics. Journal of Robotic Systems, 21(3), 95–116. https://doi.org/10.1002/rob.20002

Helicopter kinematics using Euler angles. They justify their tolerance of singularities in this model because the vehicle will never point straight up or down. Singularity occurs at theta=+-pi/2
Position of vehicle w/r/t inertial frame defined by a position vector and Euler angles.
Velocities w/r/t inertial frame and body frame.
Rigid body equations - mass/inertia matrix.
Note: I think this project should ignore all aspects of vehicle dynamics except for symplified system which considers thrust, mass and inertia in order to create a simplified model of power over a trajectory. A model involving wind, etc. would be nice but let’s be serious here.


\section{Computational Geometry}



\section{Terrain Following}

Unmanned underwater vehicles
Artificial Neural Networks
Sensors pointed fore and aft, and one pointed down.

Though there is relatively little research on the present problem -- predictive trajectory estimation based on forward-looking terrain modeling for UAV applications -- there is plenty of research on terrain avoidance for both autonomous underwater vehicles (AUVs) and ballistic missiles, as far back as the 1950s. 
AUVs
[Maybe note that underwater vehicles are a good path for study because they are larger and can carry a lot of hardware, have military significance and support, etc]

\cite{Samar2011}
Samar, R., \& Rehman, A. (2011). Autonomous terrain-following for unmanned air vehicles. Mechatronics, 21(5), 844–860. https://doi.org/10.1016/j.mechatronics.2010.09.010

Requires a pre-generated DEM
To develop a “reference trajectory in the vertical plane” that the vehicle will follow, within the constraints of the flight envelope.
Constraints on climb and descent rate [n.b. Impacts battery consumption, data quality]
Definition of trajectory error w/r/t terrain elevation.
Discusses INS drift and the role this plays in extracting accurate elevation data from DEM -- “corridor of uncertainty.”
Max elevation within a circle of uncertainty is used as the reference elevation.
Two algorithms, “Stair Algorithm” and “Spline Algorithm”.
Stair algorithm goes some way to solving the ‘valley’ problem, where a gap in surface is encountered that we don’t want to go into.
Cubic splines.
“The spline trajectory is smooth as expected and is optimal in the sense of minimizing the objective function.”
“Convergence issues” with spline.
Quality index: “the integral over range of the difference between the actual terrain and the trajectory generated by the algorithm, i.e., R edR (note that e is constrained to be positive semidefinite). “
Stair algorithm produces instantaneous changes in trajectory which:
Result in large throttle inputs (battery wasteage, etc.)
Failure to track (overshooting the corners on descent)
Tracking controller design - plant model.
Flight control hardware, software, testing, etc.

\cite{Twigg2003}
Twigg, S., Calise, A., \& Johnson, E. (2003). On-Line Trajectory Optimization for Autonomous Air Vehicles. In AIAA Guidance, Navigation, and Control Conference and Exhibit (pp. 1–9). Reston, Virigina: American Institute of Aeronautics and Astronautics. https://doi.org/10.2514/6.2003-5522

Constant-energy vs. constant velocity constraint for vertical trajectory.
Lagrangian and Hamiltonian stuff

\cite{Waldock1995}
Waldock, M. I. (1995). Terrain following control of an unmanned underwater vehicle using artificial neural networks. In IEE Colloquium on `Control and Guidance of Remotely Operated Vehicles’ (Vol. 1995, pp. 4–4). IEE. https://doi.org/10.1049/ic:19950800

\cite{Bovio2006}
Bovio, E., Cecchi, D., \& Baralli, F. (2006). Autonomous underwater vehicles for scientific and naval operations. Annual Reviews in Control, 30(2), 117–130. https://doi.org/10.1016/j.arcontrol.2006.08.003

Military AUVs - control system requirements: course-keeping, constant depth, constant altitude, noise and disturbance rejection. All relevant to UAVs.
Rejection of high-frequency noise (that is, terrain variations) in this case due, for example, to plants -- Poseidonia oceanica -- Mediterranean sea grass, leaves up to 1.5m long.
Model-dependent vs. model-independent control systems -- the former depend on accurate modeling of the physical parameters of the platform and are subject to changes. The latter is robust to platform changes but more complex to implement [or was at the time this was published…]
Control loop:

Suggest INS for best navigation system.
Kalman filter error estimation.
Instrumentation:
IMU
Speed sensor (doppler velocity log)
Depth/pressure
Independent position sensor (GPS) for initialization and error resets.

\cite{Jalving1994}
Jalving, B. (1994). The NDRE-AUV Flight Control System. IEEE Journal of Oceanic Engineering, 19(4), 497–501. https://doi.org/10.1109/48.338385

AUV using PID control with equations, etc.
Used for constant elevation (not terrain following)

NO CITE
A.J. Healey, \& Lienard, D. (1993). Multivariable sliding mode control for autonomous diving and steering of unmanned underwater vehicles. Oceanic Engineering, IEEE Journal Of, 18(3), 327–339. https://doi.org/10.1109/JOE.1993.236372

Sliding mode control, dynamic equations, etc.

\cite{Juul1994}
Juul, D. L., Mcdermott, M. E., Nelson, E. L., Barnett, D. M., \& Williams, G. N. (1994). Submersible Control Using the Linear uadratic Gaussian with Loop Transfer ecovery Metha.

\cite{FeijunSong}
Feijun Song, \& Smith, S. M. (n.d.). Design of sliding mode fuzzy controllers for an autonomous underwater vehicle without system model. OCEANS 2000 MTS/IEEE Conference and Exhibition. Conference Proceedings (Cat. No.00CH37158), 2, 835–840. https://doi.org/10.1109/OCEANS.2000.881362

\cite{Goheen1990}
Goheen, K. R., \& Jefferys, E. R. (1990). Multivariable Self-Tuning Autopilots for Autonomous and Remotely Operated Underwater Vehicles. IEEE Journal of Oceanic Engineering, 15(3), 144–151. https://doi.org/10.1109/48.107142

\section{Surface Reconstruction}

Geometric vs. statistical surface reconstruction

Berger, M., Tagliasacchi, A., Seversky, L. M., Alliez, P., Guennebaud, G., Levine, J. A., … Silva, C. T. (2017). A Survey of Surface Reconstruction from Point Clouds. Computer Graphics Forum, 36(1), 301–329. https://doi.org/10.1111/cgf.12802

Priors - the assumptions that one uses to focus the reconstruction of the surface:
“Our survey presents surface reconstruction algorithms from the perspective of priors: assumptions made by algorithms in order to combat imperfections in the point cloud and to eventually focus what information about the shape is reconstructed. Without prior assumptions, the reconstruction problem is ill-posed; an infinite number of surfaces can pass through (or near) a given set of data points”
Some priors involve low-level data characteristics. Some involve higher-level structural factors.
Constrain expectations, prioritize desireables
Eg. Dense, uniform point cloud -> smoothness prior
Studies a variety of reconstruction methods, priors and issues. 
Fairly technical.

\section{Control Systems}

There are two primary fields of control system development, model-based and reactive. Model-based systems attempt to re-create the physical forces and control inputs acting upon a vehicle in order to calculate the control inputs required to maintain a stable state. Reactive controls, on the other hand, use sensor inputs to determine the amount of error between the desired and actual states, and compute the control inputs required to reduce the error.

\subsubsection{PID Controllers}

[discuss actuator saturation and control input singularity for hard-angled trajectories, etc.]


The \emph{proportional-integral-derivative} controller (PID) is widely used in industry \cite{Soediono1989} to maintain the stability of, for example, chemical processes by measuring process outputs, calculating the error with regards to a target metric and feeding the measurements back into the controller which adjusts the input actuators. This paradigm has the advantage that it doesn’t necessarily require a comprehensive physical model of the process to succeed, only a desired outcome and the possibility of achieving that outcome by adjusting the available inputs (a closed-loop system) 	\cite{Soediono1989}. A significant advantage of PID controllers are often self-training and can be considered a form of primitive artificial intelligence.

PID controllers are ideally suited to the complex state-management tasks that face a multi-rotor UAV. In fact, controlling such an inherently-unstable vehicle would be nearly impossible without the assistance of some sort of reactive controller, even if the main controller were model based. However, it is not always possible, given changing payloads, environmental conditions, terrains and flight plans -- not to mention the availability of comprehensive models and computing power -- to accurately model a vehicle’s dynamics.

There are many books dedicated to the subject of industrial process control using PIDs which offer a grounding in the fundamental operating principles. ``ractical PID Control'' \cite{Soediono1989}, 

\begin{itemize}
\item the proportional control action;
\item the integral action; and
\item the derivative action.
\end{itemize}

General PID for Industrial Processes:
\cite{Saxena}
Chidambaram, M., \& Saxena, N. (2018). Relay Tuning of PID Controllers. Singapore: Springer Singapore. https://doi.org/10.1007/978-981-10-7727-2

Ref’ed: Handbook of PI and  PID controller tuning rules; PID control in the third millennium; Practical PID control
Plenty of different loop tuning methods.

\cite{Sanchez2012}
Sánchez, J., Visioli, A., \& Dormido, S. (2012). PID Control in the third millenium. PID Control in the Third Millennium. https://doi.org/10.1007/978-1-4471-2425-2

\cite{Soediono1989}
Soediono, B., \& Visioli, A. (2006). Practical PID Control. (Intergovernmental Panel on Climate Change, Ed.), Climate Change 2013 - The Physical Science Basis (Vol. 53). Cambridge: Springer London. https://doi.org/10.1007/1-84628-586-0


\newpage
\bibliographystyle{plain}
\bibliography{/home/rob/Documents/bibtex/library.bib}

\end{document}